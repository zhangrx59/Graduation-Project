# -*- coding: utf-8 -*-
"""
å¼‚æ­¥åç¨‹ç‰ˆï¼šQwen-VL æ‰¹é‡ç”Ÿæˆçš®æŸæ€§çŠ¶æè¿°ï¼ˆæ”¯æŒæ–­ç‚¹ç»­è·‘ï¼‰

- ä½¿ç”¨ asyncio + AsyncOpenAI å®ç°çœŸæ­£çš„å¹¶å‘è°ƒç”¨
- å¹¶å‘æ•°é‡ç”± config["analysis_config"]["max_workers"] æ§åˆ¶ï¼ˆé»˜è®¤æœ€å¤š 16ï¼‰
- è‡ªåŠ¨è·³è¿‡å·²å®Œæˆè¡Œï¼ˆlesion_shape éç©ºä¸”é errorï¼‰
- åªå¤„ç†å½“å‰å›¾ç‰‡æ–‡ä»¶å¤¹ä¸­èƒ½æ‰¾åˆ°å›¾ç‰‡çš„æ ·æœ¬
"""

import os
import base64
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Tuple

import asyncio
import pandas as pd
from openai import AsyncOpenAI


# ===================== é€šç”¨å·¥å…· =====================

def load_config(config_path: str = "config.json") -> Dict[str, Any]:
    """ä» JSON æ–‡ä»¶åŠ è½½é…ç½®"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def encode_image_to_base64(image_path: Path) -> str:
    """å°†æœ¬åœ°å›¾åƒè½¬æ¢ä¸º base64 ç¼–ç """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def build_imageid_to_path(folder_path: str, supported_formats) -> Dict[str, Path]:
    """
    æ‰«æå›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œæ„å»º {image_id(ä¸å¸¦æ‰©å±•å) -> å®Œæ•´è·¯å¾„} æ˜ å°„
    åªè¦æ–‡ä»¶åæ˜¯ XXX.jpg / XXX.pngï¼Œå°±å¯¹åº” image_id = XXX
    """
    folder = Path(folder_path)
    mapping: Dict[str, Path] = {}

    if not folder.exists():
        raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder}")

    for f in folder.iterdir():
        if f.is_file() and f.suffix.lower() in supported_formats:
            image_id = f.stem  # å»æ‰æ‰©å±•å
            mapping[image_id] = f

    print(f"ğŸ“ åœ¨ {folder_path} ä¸­å…±æ‰¾åˆ° {len(mapping)} ä¸ª image_id å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶")
    return mapping


def safe_read_table(path: str) -> pd.DataFrame:
    """
    æ—¢æ”¯æŒ csv ä¹Ÿæ”¯æŒ xlsxï¼š
    - .csv ç”¨å¤šç§ç¼–ç å°è¯•
    - .xls/.xlsx ç”¨ read_excel
    """
    ext = Path(path).suffix.lower()
    if ext in [".xls", ".xlsx"]:
        print(f"ğŸ§¾ æ£€æµ‹åˆ° Excel æ–‡ä»¶ï¼š{path}ï¼Œä½¿ç”¨ read_excel è¯»å–")
        return pd.read_excel(path)

    encodings_to_try = ["utf-8", "gbk", "gb2312", "latin1"]
    last_err = None
    for enc in encodings_to_try:
        try:
            print(f"å°è¯•ä½¿ç”¨ç¼–ç  {enc} è¯»å– CSV...")
            df = pd.read_csv(path, encoding=enc, low_memory=False)
            print(f"âœ… ä½¿ç”¨ç¼–ç  {enc} è¯»å– CSV æˆåŠŸ")
            return df
        except UnicodeDecodeError as e:
            print(f"âŒ ä½¿ç”¨ç¼–ç  {enc} å¤±è´¥: {e}")
            last_err = e

    raise last_err


# ===================== å¼‚æ­¥è°ƒç”¨ Qwen =====================

async def call_qwen_shape_async(
    client: AsyncOpenAI,
    model_type: str,
    image_path: Path,
    shape_prompt: str,
    max_retries: int = 3,
    base_retry_delay: float = 15.0,
) -> str:
    """
    å¼‚æ­¥è°ƒç”¨ Qwen-VLï¼Œè¿”å›â€œç—…å˜æ€§çŠ¶æè¿°â€çš„ç®€çŸ­ä¸­æ–‡ã€‚

    - å¸¦æœ‰é™æµå‹å¥½çš„é‡è¯•é€»è¾‘ï¼ˆ429 / TPM limitï¼‰
    - ä¸åšéšæœº sleepï¼Œè€Œæ˜¯æŒ‡æ•°å›é€€ç­‰å¾…
    """
    base64_image = encode_image_to_base64(image_path)

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": shape_prompt},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    },
                },
            ],
        }
    ]

    for attempt in range(1, max_retries + 1):
        try:
            resp = await client.chat.completions.create(
                model=model_type,
                messages=messages,
                stream=False,
            )

            content = resp.choices[0].message.content

            if isinstance(content, list):
                texts = []
                for part in content:
                    if isinstance(part, dict) and part.get("type") == "text":
                        texts.append(part.get("text", ""))
                    elif isinstance(part, str):
                        texts.append(part)
                result = "".join(texts).strip()
            else:
                result = str(content).strip()

            # åªä¿ç•™ç¬¬ä¸€è¡Œï¼Œå»æ‰å¤šä½™ç©ºç™½
            result = result.splitlines()[0].strip()
            return result

        except Exception as e:
            err_str = str(e)
            # ç®€å•åˆ¤æ–­æ˜¯å¦æ˜¯é™æµ / 429 / TPM
            if "429" in err_str or "rate limit" in err_str or "TPM limit" in err_str:
                if attempt < max_retries:
                    delay = base_retry_delay * attempt
                    print(f"âš ï¸ æ£€æµ‹åˆ°é™æµï¼Œ{attempt}/{max_retries} æ¬¡ï¼Œç­‰å¾… {delay:.1f}s åé‡è¯•...")
                    await asyncio.sleep(delay)
                    continue
            # éé™æµé”™è¯¯ æˆ– æœ€åä¸€è½®é‡è¯•å¤±è´¥ï¼Œç›´æ¥æŠ›å‡º
            raise


# ===================== å¼‚æ­¥ worker =====================

async def worker_task_async(
    task_idx: int,
    row_idx: int,
    image_id: str,
    image_path: Path,
    client: AsyncOpenAI,
    model_type: str,
    shape_prompt: str,
    semaphore: asyncio.Semaphore,
) -> Tuple[int, str, str, str]:
    """
    å•ä¸ªå¼‚æ­¥ä»»åŠ¡ï¼š
    - ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶åŒæ—¶åœ¨é£çš„è¯·æ±‚æ•°ï¼ˆå¹¶å‘æ•°ï¼‰
    - è°ƒç”¨ call_qwen_shape_async
    - è¿”å› (row_idx, image_id, shape, error)
    """
    async with semaphore:
        try:
            print(f"ğŸ§µ[ä»»åŠ¡{task_idx}] å¼€å§‹å¤„ç† image_id={image_id}, æ–‡ä»¶={image_path.name}")
            shape = await call_qwen_shape_async(client, model_type, image_path, shape_prompt)
            return row_idx, image_id, shape, ""
        except Exception as e:
            err_str = str(e)
            print(f"âŒ[ä»»åŠ¡{task_idx}] image_id={image_id} è°ƒç”¨å¤±è´¥: {err_str}")
            return row_idx, image_id, f"error:{err_str}", err_str


# ===================== ä¸»æµç¨‹ï¼ˆå¼‚æ­¥ï¼‰ =====================

async def annotate_image_shapes_async(
    config_path: str = "config.json",
    output_path: str = None,
    save_every_n: int = 20,
):
    """
    ä¸»é€»è¾‘ï¼š
    - è¯»å–è¡¨æ ¼ & å›¾ç‰‡åˆ—è¡¨
    - æ£€æµ‹å“ªäº›è¡Œå·²ç»å®Œæˆ / æœªå®Œæˆ
    - å¯¹æœªå®Œæˆéƒ¨åˆ†æ„å»ºä»»åŠ¡åˆ—è¡¨
    - ä½¿ç”¨ asyncio å¹¶å‘è°ƒ Qwenï¼Œå¡«å…… lesion_shape
    """
    config = load_config(config_path)
    api_config = config["api_config"]
    analysis_config = config["analysis_config"]
    prompts_config = config.get("prompts", {})

    folder_path = analysis_config["folder_path"]
    table_path = analysis_config["csv_file_path"]
    supported_formats = [s.lower() for s in analysis_config["supported_formats"]]

    image_id_column = analysis_config.get("image_id_column", None)
    shape_prompt = prompts_config.get(
        "shape_prompt",
        "ä½ æ˜¯ä¸€åçš®è‚¤ç§‘åŒ»ç”Ÿï¼Œè¯·ç”¨ä¸­æ–‡ç®€è¦æè¿°çš®æŸæ€§çŠ¶ã€‚"
    )

    # 1. è¯»å–è¡¨æ ¼ï¼ˆCSV / Excelï¼‰
    df = safe_read_table(table_path)
    print(f"ğŸ“Š æˆåŠŸåŠ è½½è¡¨æ ¼ï¼Œè®°å½•æ•°ï¼š{len(df)}")
    print(f"å½“å‰åˆ—åï¼š{df.columns.tolist()}")

    # è‡ªåŠ¨æ£€æµ‹ image_id åˆ—
    if image_id_column is None or image_id_column not in df.columns:
        if "å›¾ç‰‡ID" in df.columns:
            image_id_column = "å›¾ç‰‡ID"
            print("â„¹ï¸ æœªåœ¨ config ä¸­æ‰¾åˆ°å¯ç”¨çš„ image_id_columnï¼Œè‡ªåŠ¨ä½¿ç”¨åˆ—åï¼šå›¾ç‰‡ID")
        else:
            raise ValueError(
                f"åœ¨è¡¨æ ¼ä¸­æœªæ‰¾åˆ°é…ç½®çš„ image_id_columnï¼Œä¹Ÿä¸å­˜åœ¨â€œå›¾ç‰‡IDâ€è¿™ä¸€åˆ—ï¼Œè¯·æ£€æŸ¥ï¼šç°æœ‰åˆ—ä¸º {df.columns.tolist()}"
            )
    print(f"ğŸ‘‰ å°†ä½¿ç”¨åˆ— {image_id_column!r} ä½œä¸ºå›¾ç‰‡ ID åˆ—")

    # lesion_shape åˆ—
    if "lesion_shape" not in df.columns:
        df["lesion_shape"] = ""
        print("ğŸ†• æ–°å¢åˆ— lesion_shape ç”¨äºä¿å­˜ç—…å˜æ€§çŠ¶æè¿°")
    else:
        print("â„¹ï¸ å·²å­˜åœ¨åˆ— lesion_shapeï¼Œå°†åœ¨å…¶åŸºç¡€ä¸Šè¡¥å…¨/è¦†ç›–ç©ºå€¼")

    # æ–­ç‚¹ç»­è·‘ï¼šç»Ÿè®¡å®Œæˆ / æœªå®Œæˆ
    col = df["lesion_shape"].astype(str)
    finished_mask = col.str.strip().ne("") & ~col.str.startswith("error:")
    unfinished_mask = ~finished_mask

    finished_count = int(finished_mask.sum())
    unfinished_count = int(unfinished_mask.sum())
    print(f"âœ… å·²å®Œæˆæ ·æœ¬ï¼ˆlesion_shape éç©ºä¸”é errorï¼‰: {finished_count}")
    print(f"â³ æœªå®Œæˆæ ·æœ¬ï¼ˆç©ºç™½æˆ– errorï¼Œå°†ç»§ç»­è¯Šæ–­ï¼‰: {unfinished_count}")

    if unfinished_count == 0:
        print("ğŸ‰ æ‰€æœ‰è¡Œéƒ½å·²ç»æœ‰ lesion_shape ç»“æœï¼Œæ— éœ€ç»§ç»­è¯Šæ–­ã€‚")
        return

    # 2. æ„å»º image_id -> image_path æ˜ å°„
    imageid_to_path = build_imageid_to_path(folder_path, set(supported_formats))

    # 3. æ„å»ºä»»åŠ¡åˆ—è¡¨ï¼ˆåªå¤„ç† æœªå®Œæˆ ä¸” æœ‰å›¾ç‰‡ çš„è¡Œï¼‰
    tasks_meta: List[Tuple[int, str, Path]] = []
    for row_idx, row in df[unfinished_mask].iterrows():
        image_id = str(row[image_id_column])
        image_path = imageid_to_path.get(image_id)

        if image_path is None:
            print(f"âš ï¸ row_idx={row_idx}, image_id={image_id} åœ¨æ–‡ä»¶å¤¹ä¸­æ‰¾ä¸åˆ°å¯¹åº”å›¾ç‰‡ï¼Œæ ‡è®°ä¸º image_not_found")
            df.at[row_idx, "lesion_shape"] = "image_not_found"
            continue

        tasks_meta.append((row_idx, image_id, image_path))

    total_tasks = len(tasks_meta)
    print(f"ğŸ§¾ æœ¬æ¬¡å®é™…éœ€è¦è°ƒç”¨å¤§æ¨¡å‹çš„æ ·æœ¬æ•°ï¼š{total_tasks}")
    if total_tasks == 0:
        print("âš ï¸ æœªå®Œæˆçš„è¡Œä¸­ï¼Œæ²¡æœ‰ä»»ä½•ä¸€è¡Œèƒ½åœ¨å›¾ç‰‡æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°å›¾ç‰‡ã€‚ç›´æ¥ä¿å­˜é€€å‡ºã€‚")
        out = output_path or table_path
        df.to_csv(out, index=False, encoding="utf-8-sig")
        print(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°ï¼š{out}")
        return

    # 4. åˆ›å»º AsyncOpenAI å®¢æˆ·ç«¯ï¼ˆå¤š keyï¼‰
    api_keys: List[str] = api_config["api_keys"]
    if len(api_keys) == 0:
        raise RuntimeError("config.json ä¸­ api_config.api_keys ä¸ºç©ºï¼Œè¯·é…ç½®è‡³å°‘ä¸€ä¸ª keyã€‚")

    max_workers_conf = analysis_config.get("max_workers", 16)
    # è¿™é‡Œçš„ num_workers æ˜¯æœ€å¤§å¹¶å‘è¯·æ±‚æ•°ï¼ˆå¯ä»¥æ ¹æ®å®é™…é™æµæƒ…å†µé€‚å½“è°ƒå°ï¼Œæ¯”å¦‚ 8ï¼‰
    num_workers = min(16, len(api_keys), max_workers_conf)
    print(f"ğŸ”‘ å°†ä½¿ç”¨ {num_workers} ä¸ª API keyï¼Œå¹¶å‘ä¸Šé™ = {num_workers}")

    used_keys = api_keys[:num_workers]
    clients: List[AsyncOpenAI] = [
        AsyncOpenAI(api_key=k, base_url=api_config["base_url"]) for k in used_keys
    ]

    semaphore = asyncio.Semaphore(num_workers)

    # 5. æ„å»ºæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
    start_time = time.time()
    coros = []
    for task_idx, (row_idx, image_id, image_path) in enumerate(tasks_meta):
        client = clients[task_idx % num_workers]
        coro = worker_task_async(
            task_idx=task_idx,
            row_idx=row_idx,
            image_id=image_id,
            image_path=image_path,
            client=client,
            model_type=api_config["model_type"],
            shape_prompt=shape_prompt,
            semaphore=semaphore,
        )
        coros.append(coro)

    # 6. å¹¶å‘æ‰§è¡Œ + ç»“æœå†™å› DataFrame
    completed = 0
    for fut in asyncio.as_completed(coros):
        row_idx, image_id, shape, err = await fut
        df.at[row_idx, "lesion_shape"] = shape
        completed += 1

        if err == "":
            print(f"âœ… [{completed}/{total_tasks}] image_id={image_id} å½¢çŠ¶: {shape}")
        else:
            print(f"âŒ [{completed}/{total_tasks}] image_id={image_id} å‡ºé”™: {err}")

        if completed % save_every_n == 0:
            tmp_out = output_path or table_path.replace(".csv", "_with_shape.csv")
            df.to_csv(tmp_out, index=False, encoding="utf-8-sig")
            print(f"ğŸ’¾ å·²ä¿å­˜ä¸­é—´ç»“æœåˆ° {tmp_out}")

    end_time = time.time()

    # 7. å…³é—­æ‰€æœ‰ AsyncOpenAI å®¢æˆ·ç«¯çš„åº•å±‚ä¼šè¯
    for c in clients:
        await c.close()

    # 8. æœ€ç»ˆä¿å­˜
    final_out = output_path or table_path.replace(".csv", "_with_shape.csv")
    df.to_csv(final_out, index=False, encoding="utf-8-sig")
    print(f"\nğŸ‰ æœ¬æ¬¡æœªå®Œæˆéƒ¨åˆ†å…¨éƒ¨è¯Šæ–­å®Œæˆï¼")
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°ï¼š{final_out}")
    print(f"â±ï¸ æœ¬æ¬¡å¤„ç†è€—æ—¶: {end_time - start_time:.2f} ç§’ï¼Œå¹³å‡æ¯ä¸ªæ ·æœ¬ {(end_time - start_time) / max(total_tasks, 1):.2f} ç§’")


# ===================== åŒæ­¥å…¥å£ =====================

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨çš®è‚¤ç—…å˜â€œæ€§çŠ¶â€æ ‡æ³¨ç¨‹åºï¼ˆå¼‚æ­¥åç¨‹ç‰ˆï¼Œæ–­ç‚¹ç»­è·‘ï¼‰...")
    asyncio.run(annotate_image_shapes_async("config.json"))
    print("âœ… å…¨éƒ¨å®Œæˆã€‚")
