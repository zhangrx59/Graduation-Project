# finetune_medgemma_lora_from_metadata.py
# -*- coding: utf-8 -*-

import os
from dataclasses import dataclass
from typing import Dict, Any

import torch
from torch.utils.data import Dataset
from PIL import Image

from datasets import load_dataset
from transformers import (
    AutoModelForImageTextToText,
    AutoProcessor,
    BitsAndBytesConfig,
    TrainingArguments,
    Trainer,
)
from peft import (
    LoraConfig,
    get_peft_model,
    prepare_model_for_kbit_training,
)


# ===================== 0. é…ç½®åŒºåŸŸï¼šä½ éœ€è¦æ”¹çš„åœ°æ–¹ =====================

# åŸºç¡€æ¨¡å‹
BASE_MODEL = "google/medgemma-4b-it"

# ä½ çš„ metadata CSVï¼ˆå°±æ˜¯ metadata_isic_with_shape.csvï¼‰
METADATA_CSV = r"C:\Users\zhangrx59\PycharmProjects\liandan\metadata_isic_with_shape.csv"

# å›¾ç‰‡æ‰€åœ¨æ ¹ç›®å½• + åç¼€
# å‡è®¾ä½ çš„å›¾ç‰‡æ–‡ä»¶åæ˜¯: PAT_46_881_939.jpg è¿™æ ·çš„å½¢å¼
IMAGE_ROOT_DIR = r"C:\Users\zhangrx59\PycharmProjects\liandan\ISIC_dataset2"
IMAGE_EXT = ".jpg"   # å¦‚æœæ˜¯ .png å°±æ”¹æˆ ".png"

# CSV ä¸­åˆ—åï¼ˆæ¥è‡ªä½ åˆšæä¾›çš„è¡¨ï¼‰
COL_IMAGE_ID    = "å›¾ç‰‡ID"
COL_AGE         = "å¹´é¾„"
COL_SEX         = "æ€§åˆ«"
COL_FATHER_ORI  = "çˆ¶ç±è´¯"
COL_MOTHER_ORI  = "æ¯ç±è´¯"
COL_BIOPSY      = "æ˜¯å¦æ´»æ£€"
COL_SMOKE       = "æ˜¯å¦å¸çƒŸ"
COL_DRINK       = "æ˜¯å¦é¥®é…’"
COL_PESTICIDE   = "å†œè¯"
COL_SKIN_CANCER = "çš®è‚¤ç™Œç—…å²"
COL_OTHER_CA    = "ç™Œç—‡ç—…å²"
COL_TAP_WATER   = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰è‡ªæ¥æ°´"
COL_SEWER       = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰ä¸‹æ°´é“"
COL_PHOTOTYPE   = "çš®è‚¤å…‰å‹"
COL_REGION      = "åŒºåŸŸ"
COL_D1          = "ç›´å¾„1"
COL_D2          = "ç›´å¾„2"
COL_PRURITUS    = "ç˜™ç—’"
COL_GROWTH      = "æ˜¯å¦é•¿å¤§"
COL_PAIN        = "ç–¼ç—›"
COL_MORPH_CHANGE= "å½¢æ€å˜åŒ–"
COL_BLEEDING    = "å‡ºè¡€"
COL_ELEVATED    = "æ˜¯å¦éš†èµ·"
COL_TARGET      = "lesion_shape"   # ç›®æ ‡è¾“å‡ºåˆ—ï¼ˆä½ ä¹‹å‰ç”Ÿæˆçš„å½¢æ€æè¿°ï¼‰

# LoRA adapter è¾“å‡ºç›®å½•
OUTPUT_DIR = r"C:\Users\zhangrx59\PycharmProjects\liandan\medgemma_lora_derm_from_metadata"


# ===================== 1. æŠŠå¤šåˆ—ç—…å†ä¿¡æ¯ -> ä¸€æ®µä¸­æ–‡ç—…å†æ‘˜è¦ =====================

def yn_str(v, yes="æœ‰", no="æ— ", unk="ä¸è¯¦"):
    """
    æŠŠ True/False/'TRUE'/'FALSE'/'UNK'/NaN ç»Ÿä¸€è½¬æˆä¸­æ–‡ â€œæœ‰/æ— /ä¸è¯¦â€
    """
    if isinstance(v, str):
        vs = v.strip().upper()
        if vs in ["TRUE", "T", "YES", "Y"]:
            return yes
        if vs in ["FALSE", "F", "NO", "N"]:
            return no
        if vs in ["UNK", "UNKNOWN", "NA", "NAN", "NONE", ""]:
            return unk
    if isinstance(v, (bool, int)):
        return yes if bool(v) else no
    if v != v:  # NaN
        return unk
    return str(v)


def build_clinical_note(row) -> str:
    """
    æ ¹æ®ä½ è¡¨ä¸­çš„å¤šåˆ—å­—æ®µï¼Œè‡ªåŠ¨æ‹¼æ¥æˆä¸€æ®µä¸­æ–‡ç—…å†æ‘˜è¦æ–‡æœ¬ã€‚
    ä½ å¯ä»¥æ ¹æ®å–œå¥½åœ¨è¿™é‡Œå¾®è°ƒæªè¾ã€‚
    """
    age = row.get(COL_AGE, "")
    sex = str(row.get(COL_SEX, "") or "").strip()
    region = str(row.get(COL_REGION, "") or "").strip()
    father_ori = str(row.get(COL_FATHER_ORI, "") or "").strip()
    mother_ori = str(row.get(COL_MOTHER_ORI, "") or "").strip()

    skin_ca = yn_str(row.get(COL_SKIN_CANCER))
    other_ca = yn_str(row.get(COL_OTHER_CA))
    smoke = yn_str(row.get(COL_SMOKE), yes="å¸çƒŸ", no="ä¸å¸çƒŸ")
    drink = yn_str(row.get(COL_DRINK), yes="é¥®é…’", no="ä¸é¥®é…’")
    pesticide = yn_str(row.get(COL_PESTICIDE), yes="æœ‰å†œè¯æ¥è§¦å²", no="æ— å†œè¯æ¥è§¦å²")

    tap = yn_str(row.get(COL_TAP_WATER), yes="æœ‰è‡ªæ¥æ°´", no="æ— è‡ªæ¥æ°´")
    sewer = yn_str(row.get(COL_SEWER), yes="æœ‰ä¸‹æ°´é“", no="æ— ä¸‹æ°´é“")

    phototype = row.get(COL_PHOTOTYPE, "")
    d1 = row.get(COL_D1, "")
    d2 = row.get(COL_D2, "")

    pruritus = yn_str(row.get(COL_PRURITUS))
    growth = yn_str(row.get(COL_GROWTH))
    pain = yn_str(row.get(COL_PAIN))
    morph_change = yn_str(row.get(COL_MORPH_CHANGE))
    bleeding = yn_str(row.get(COL_BLEEDING))
    elevated = yn_str(row.get(COL_ELEVATED))

    # æ€§åˆ«æ±‰åŒ–
    if sex.upper() in ["MALE", "M"]:
        sex_cn = "ç”·æ€§"
    elif sex.upper() in ["FEMALE", "F"]:
        sex_cn = "å¥³æ€§"
    else:
        sex_cn = sex or "æ€§åˆ«ä¸è¯¦"

    # éƒ¨ä½
    region_cn = region or "éƒ¨ä½ä¸è¯¦"

    # ç›´å¾„
    size_str = ""
    if d1 and d2:
        size_str = f"çš®æŸçº¦ {d1}Ã—{d2} mm"
    elif d1:
        size_str = f"çš®æŸæœ€å¤§å¾„çº¦ {d1} mm"

    # çš®è‚¤å…‰å‹ï¼ˆç®€å•ç›´æ¥ç”¨æ•°å­—ï¼‰
    photo_str = f"çš®è‚¤å…‰å‹ï¼š{phototype} å‹" if phototype != "" else ""

    # å‡ºèº«åœ°
    origin_str = ""
    if father_ori or mother_ori:
        origin_str = f"çˆ¶ç±è´¯ï¼š{father_ori}ï¼Œæ¯ç±è´¯ï¼š{mother_ori}ã€‚"

    # ç»„ç»‡ä¸€ä¸ªç¨å¾®è§„æ•´ä¸€ç‚¹çš„ä¸­æ–‡ç—…å†æ‘˜è¦
    parts = []

    parts.append(f"{age}å²{sex_cn}ï¼Œ{region_cn}çš®è‚¤ç—…å˜ã€‚")
    if size_str:
        parts.append(size_str + "ã€‚")
    if origin_str:
        parts.append(origin_str)

    parts.append(f"æ—¢å¾€çš®è‚¤ç™Œç—…å²ï¼š{skin_ca}ï¼›å…¶ä»–æ¶æ€§è‚¿ç˜¤ç—…å²ï¼š{other_ca}ã€‚")
    parts.append(f"ç”Ÿæ´»æ–¹å¼ï¼š{smoke}ï¼Œ{drink}ï¼Œ{pesticide}ã€‚")
    parts.append(f"å±…ä½ç¯å¢ƒï¼š{tap}ï¼Œ{sewer}ã€‚")
    if photo_str:
        parts.append(photo_str + "ã€‚")

    parts.append(
        f"ç—‡çŠ¶ä½“å¾ï¼šç˜™ç—’{pruritus}ï¼Œæ˜¯å¦é•¿å¤§{growth}ï¼Œç–¼ç—›{pain}ï¼Œå½¢æ€å˜åŒ–{morph_change}ï¼Œå‡ºè¡€{bleeding}ï¼Œéš†èµ·{elevated}ã€‚"
    )

    note = "".join(parts)
    return note


# ===================== 2. æ•°æ®é›†å®šä¹‰ï¼šç›´æ¥ç”¨ metadata_isic_with_shape.csv =====================

class DermMetadataDataset(Dataset):
    """
    ç›´æ¥åŸºäº metadata_isic_with_shape.csv çš„ Datasetï¼š
    - image: ç”± å›¾ç‰‡ID + IMAGE_ROOT_DIR + IMAGE_EXT æ‹¼è·¯å¾„
    - clinical_note: ç”±å¤šåˆ—å­—æ®µè‡ªåŠ¨æ‹¼æ¥
    - target_text: lesion_shapeï¼ˆçš®æŸæ€§çŠ¶æè¿°ï¼‰
    """
    def __init__(self, hf_dataset):
        self.ds = hf_dataset

    def __len__(self):
        return len(self.ds)

    def __getitem__(self, idx):
        row = self.ds[idx]

        image_id = str(row[COL_IMAGE_ID])
        image_path = os.path.join(IMAGE_ROOT_DIR, image_id + IMAGE_EXT)

        image = Image.open(image_path).convert("RGB")

        clinical_note = build_clinical_note(row)
        target_text = row[COL_TARGET]

        messages = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "You are a dermatology assistant. "
                            "Given the clinical note and the skin lesion image, "
                            "describe the visible lesion findings in Chinese, focusing on morphology "
                            "and appearance (size, number, color, shape, border, surface, elevation, etc.). "
                            "Do NOT give a diagnosis, only describe what you see."
                        ),
                    }
                ],
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "ä¸´åºŠç—…å†æ‘˜è¦å¦‚ä¸‹ï¼š\n"
                            f"{clinical_note}\n\n"
                            "è¯·ç»“åˆç—…å†å’Œå›¾ç‰‡ï¼Œä½¿ç”¨ä¸­æ–‡ç®€è¦æè¿°çš®è‚¤ç—…å˜çš„è‚‰çœ¼æ‰€è§æ€§çŠ¶ï¼š"
                        ),
                    },
                    {"type": "image", "image": image},
                ],
            },
        ]

        return {
            "messages": messages,
            "image": image,
            "target_text": target_text,
        }


# ===================== 3. collatorï¼šç”¨ AutoProcessor ç»Ÿä¸€æ‰“åŒ…å¤šæ¨¡æ€ =====================

@dataclass
class MedGemmaCollator:
    processor: AutoProcessor

    def __call__(self, batch) -> Dict[str, Any]:
        images = [eg["image"] for eg in batch]
        messages_list = [eg["messages"] for eg in batch]
        targets = [eg["target_text"] for eg in batch]

        texts = []
        for msgs, tgt in zip(messages_list, targets):
            chat_text = self.processor.apply_chat_template(
                msgs,
                add_generation_prompt=False,
                tokenize=False,
            )
            full_text = chat_text + tgt
            texts.append(full_text)

        model_inputs = self.processor(
            text=texts,
            images=images,
            padding=True,
            truncation=True,
            return_tensors="pt",
        )

        labels = model_inputs["input_ids"].clone()
        labels[labels == self.processor.tokenizer.pad_token_id] = -100

        model_inputs["labels"] = labels
        return model_inputs


# ===================== 4. åŠ è½½æ¨¡å‹ + LoRA (QLoRA) =====================

def load_model_and_processor():
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_use_double_quant=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16,
    )

    print("ğŸ”§ åŠ è½½ MedGemma åŸºç¡€æ¨¡å‹ï¼ˆ4bit QLoRAï¼‰...")
    model = AutoModelForImageTextToText.from_pretrained(
        BASE_MODEL,
        quantization_config=bnb_config,
        device_map="auto",
    )

    processor = AutoProcessor.from_pretrained(BASE_MODEL)
    processor.tokenizer.padding_side = "right"

    lora_config = LoraConfig(
        r=16,
        lora_alpha=16,
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM",
        target_modules="all-linear",
    )

    model = prepare_model_for_kbit_training(model)
    model = get_peft_model(model, lora_config)

    trainable, total = 0, 0
    for _, p in model.named_parameters():
        total += p.numel()
        if p.requires_grad:
            trainable += p.numel()
    print(f"ğŸ“Š æ€»å‚æ•°: {total/1e6:.1f}M, å¯è®­ç»ƒ(LoRA): {trainable/1e6:.1f}M")

    return model, processor


# ===================== 5. ä¸»è®­ç»ƒå…¥å£ =====================

def main():
    # 1) è¯»å– csv åˆ° HF Datasetï¼Œç„¶åè‡ªåŠ¨åˆ‡ train/val
    raw = load_dataset("csv", data_files={"all": METADATA_CSV})["all"]
    split = raw.train_test_split(test_size=0.1, seed=42)
    train_hf = split["train"]
    val_hf = split["test"]

    train_ds = DermMetadataDataset(train_hf)
    val_ds = DermMetadataDataset(val_hf)

    model, processor = load_model_and_processor()
    collator = MedGemmaCollator(processor=processor)

    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        num_train_epochs=2,
        per_device_train_batch_size=1,
        per_device_eval_batch_size=1,
        gradient_accumulation_steps=8,
        learning_rate=1e-4,
        logging_steps=10,
        save_steps=200,
        eval_strategy="steps",
        eval_steps=200,
        save_total_limit=2,
        bf16=True,
        report_to="none",
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_ds,
        eval_dataset=val_ds,
        data_collator=collator,
    )

    trainer.train()

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    model.save_pretrained(OUTPUT_DIR)
    processor.save_pretrained(OUTPUT_DIR)
    print(f"âœ… LoRA adapter å·²ä¿å­˜åˆ°: {OUTPUT_DIR}")


if __name__ == "__main__":
    main()
