import os
import base64
import json
import pandas as pd
import multiprocessing
import time
import re
from pathlib import Path
from multiprocessing import Pool
from openai import OpenAI
from collections import Counter

 
def load_config(config_path="config.json"):
    """ä»JSONæ–‡ä»¶åŠ è½½é…ç½®"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ {config_path} æœªæ‰¾åˆ°")
        raise
    except json.JSONDecodeError:
        print(f"é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ {config_path} æ ¼å¼ä¸æ­£ç¡®")
        raise


def encode_image_to_base64(image_path):
    """å°†æœ¬åœ°å›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def load_patient_data(csv_path):
    """
    åŠ è½½æ‚£è€…ä¸´åºŠæ•°æ®ï¼ŒåŒ…æ‹¬çœŸå®æ ‡ç­¾
    """
    try:
        df = pd.read_csv(csv_path)
        print(f"æˆåŠŸåŠ è½½æ‚£è€…æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
        print(f"æ•°æ®åˆ—: {df.columns.tolist()}")
        return df
    except Exception as e:
        print(f"åŠ è½½æ‚£è€…æ•°æ®å¤±è´¥: {e}")
        return None


def create_multimodal_prompt(clinical_data, config):
    """
    ä»configä¸­è¯»å–æ‰€æœ‰æç¤ºè¯ç»„ä»¶ï¼Œæ„å»ºå®Œæ•´çš„å¤šæ¨¡æ€æç¤ºè¯
    """
    prompts_config = config["prompts"]

    clinical_info = ""
    if clinical_data is not None:
        clinical_info = "æ‚£è€…ä¸´åºŠä¿¡æ¯ï¼š\n"

        # å¹´é¾„
        if 'age' in clinical_data and pd.notna(clinical_data['age']):
            age = clinical_data['age']
            clinical_info += f"- å¹´é¾„: {age} å²\n"

        # æ€§åˆ«
        if 'sex' in clinical_data and pd.notna(clinical_data['sex']):
            sex = clinical_data['sex']
            sex_display = "ç”·æ€§" if sex.lower() in ['male', 'm'] else "å¥³æ€§" if sex.lower() in ['female', 'f'] else sex
            clinical_info += f"- æ€§åˆ«: {sex_display}\n"

        # ç—…å˜éƒ¨ä½
        if 'localization' in clinical_data and pd.notna(clinical_data['localization']):
            localization = clinical_data['localization']
            localization_mapping = {
                'back': 'èƒŒéƒ¨', 'lower extremity': 'ä¸‹è‚¢', 'face': 'é¢éƒ¨',
                'trunk': 'èº¯å¹²', 'chest': 'èƒ¸éƒ¨', 'unknown': 'æœªçŸ¥éƒ¨ä½',
                'upper extremity': 'ä¸Šè‚¢', 'abdomen': 'è…¹éƒ¨', 'foot': 'è¶³éƒ¨'
            }
            loc_display = localization_mapping.get(localization, localization)
            clinical_info += f"- ç—…å˜éƒ¨ä½: {loc_display}\n"

    # æ„å»ºåˆ†ææ­¥éª¤
    analysis_steps = "\n".join([f"{i + 1}. {step}" for i, step in enumerate(prompts_config["analysis_steps"])])

    # æ„å»ºç–¾ç—…ç±»åˆ«
    disease_categories = "\n".join(
        [f"- {name} ({code})" for code, name in prompts_config["disease_categories"].items()])

    # æ„å»ºå®Œæ•´æç¤ºè¯ - å¼ºè°ƒåªè¾“å‡ºç—…å˜ç±»å‹
    full_prompt = f"""{prompts_config["base_prompt"]}

{clinical_info}

è¯·åŸºäºä»¥ä¸Šä¸´åºŠä¿¡æ¯å’Œçš®è‚¤ç—…å˜å›¾åƒï¼Œè¿›è¡Œç»¼åˆåˆ†æï¼š

åˆ†ææ­¥éª¤ï¼š
{analysis_steps}

å¯é€‰è¯Šæ–­ç±»åˆ«ï¼š
{disease_categories}

{prompts_config["output_requirement"]}

é‡è¦ï¼šè¯·åªè¾“å‡ºæœ€ç»ˆçš„ç—…å˜ç±»å‹è‹±æ–‡ç¼©å†™ï¼Œä¸è¦è¾“å‡ºå…¶ä»–ä»»ä½•å†…å®¹ã€‚"""

    return full_prompt


def find_patient_data_by_image_id(patient_df, image_filename, image_id_column='image_id'):
    """
    æ ¹æ®å›¾ç‰‡æ–‡ä»¶åæŸ¥æ‰¾å¯¹åº”çš„æ‚£è€…æ•°æ®
    è¿”å›ä¸´åºŠæ•°æ®å’ŒçœŸå®æ ‡ç­¾ï¼Œä½†çœŸå®æ ‡ç­¾ä¸ç”¨äºæç¤ºè¯
    """
    if patient_df is None:
        return None, None

    # ä»å›¾ç‰‡æ–‡ä»¶åæå–image_idï¼ˆå»æ‰æ‰©å±•åï¼‰
    image_id = Path(image_filename).stem

    # åœ¨image_idåˆ—ä¸­ç²¾ç¡®åŒ¹é…
    if image_id_column in patient_df.columns:
        match = patient_df[patient_df[image_id_column] == image_id]
        if not match.empty:
            # è¿”å›ä¸´åºŠæ•°æ®ï¼ˆç”¨äºæç¤ºè¯ï¼‰å’ŒçœŸå®æ ‡ç­¾ï¼ˆç”¨äºæ¯”è¾ƒï¼‰
            clinical_data = match.iloc[0][['age', 'sex', 'localization']].to_dict()
            true_label = match.iloc[0]['dx']  # çœŸå®æ ‡ç­¾
            return clinical_data, true_label

    return None, None


def extract_diagnosis_from_response(response_text):
    """
    ä»å¤§æ¨¡å‹å“åº”ä¸­æå–è¯Šæ–­ç»“æœ - ä¿æŒä½¿ç”¨dx:å‰ç¼€
    """
    diagnosis_codes = ['dx:akiec', 'dx:bcc', 'dx:bkl', 'dx:df', 'dx:nv', 'dx:mel', 'dx:vasc']

    # è½¬æ¢ä¸ºå°å†™ä¾¿äºåŒ¹é…
    text_lower = response_text.lower()

    # æŸ¥æ‰¾æ‰€æœ‰å‡ºç°çš„è¯Šæ–­ä»£ç 
    found_codes = []
    for code in diagnosis_codes:
        if re.search(r'\b' + code + r'\b', text_lower):
            found_codes.append(code)

    # æ ¹æ®å‡ºç°ä½ç½®å’Œé¢‘ç‡åˆ¤æ–­ä¸»è¦è¯Šæ–­
    if len(found_codes) == 0:
        return "unknown"
    elif len(found_codes) == 1:
        return found_codes[0]
    else:
        # å¦‚æœæœ‰å¤šä¸ªè¯Šæ–­ï¼Œé€‰æ‹©æœ€åä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆç»“è®ºï¼‰
        return found_codes[-1]


def analyze_single_image_multimodal(args):
    """
    å•å¼ å›¾ç‰‡çš„å¤šæ¨¡æ€åˆ†æä»»åŠ¡
    å‚æ•°: (image_path, config, api_key, base_url, model_type, process_id, output_dir, patient_df, image_id_column)
    """
    image_path, config, api_key, base_url, model_type, process_id, output_dir, patient_df, image_id_column = args

    current_process = multiprocessing.current_process()
    pid = current_process.pid
    image_filename = image_path.name

    # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / f"process_{process_id}_output.txt"

    print(f"âš¡ [è¿›ç¨‹{process_id} PID:{pid}] å¼€å§‹åˆ†æ: {image_filename}")

    # æŸ¥æ‰¾æ‚£è€…ä¸´åºŠæ•°æ®å’ŒçœŸå®æ ‡ç­¾
    clinical_data, true_label = find_patient_data_by_image_id(patient_df, image_filename, image_id_column)

    # åˆ›å»ºå¤šæ¨¡æ€æç¤ºè¯
    multimodal_prompt = create_multimodal_prompt(clinical_data, config)

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(api_key=api_key, base_url=base_url)

    # å°†å›¾åƒè½¬æ¢ä¸º base64
    base64_image = encode_image_to_base64(image_path)

    try:
        # å‘è¾“å‡ºæ–‡ä»¶å†™å…¥å¼€å§‹ä¿¡æ¯
        with open(output_file, 'a', encoding='utf-8') as f:
            f.write(f"\n{'=' * 60}\n")
            f.write(f"å›¾ç‰‡: {image_filename}\n")
            f.write(f"è¿›ç¨‹: {process_id} (PID: {pid})\n")
            f.write(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")

            if clinical_data:
                f.write(f"\næ‚£è€…ä¸´åºŠä¿¡æ¯:\n")
                if 'age' in clinical_data and pd.notna(clinical_data['age']):
                    f.write(f"  å¹´é¾„: {clinical_data['age']} å²\n")
                if 'sex' in clinical_data and pd.notna(clinical_data['sex']):
                    sex_display = "ç”·æ€§" if clinical_data['sex'].lower() in ['male', 'm'] else "å¥³æ€§" if clinical_data[
                                                                                                             'sex'].lower() in [
                                                                                                             'female',
                                                                                                             'f'] else \
                        clinical_data['sex']
                    f.write(f"  æ€§åˆ«: {sex_display}\n")
                if 'localization' in clinical_data and pd.notna(clinical_data['localization']):
                    loc_mapping = {
                        'back': 'èƒŒéƒ¨', 'lower extremity': 'ä¸‹è‚¢', 'face': 'é¢éƒ¨',
                        'trunk': 'èº¯å¹²', 'chest': 'èƒ¸éƒ¨', 'unknown': 'æœªçŸ¥éƒ¨ä½',
                        'upper extremity': 'ä¸Šè‚¢', 'abdomen': 'è…¹éƒ¨', 'foot': 'è¶³éƒ¨'
                    }
                    loc_display = loc_mapping.get(clinical_data['localization'], clinical_data['localization'])
                    f.write(f"  ç—…å˜éƒ¨ä½: {loc_display}\n")
            else:
                f.write(f"æ‚£è€…ä¸´åºŠä¿¡æ¯: æœªæ‰¾åˆ°å¯¹åº”æ•°æ®\n")

            f.write(f"{'=' * 60}\n")

        # å‘æ¨¡å‹å‘é€å¤šæ¨¡æ€è¯·æ±‚
        response = client.chat.completions.create(
            model=model_type,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": multimodal_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ],
            stream=True,
        )

        # æ”¶é›†å“åº”å†…å®¹
        full_response = ""
        for chunk in response:
            if not chunk.choices:
                continue
            delta = chunk.choices[0].delta
            if delta.content:
                content = delta.content
                full_response += content
            if hasattr(delta, "reasoning_content") and delta.reasoning_content:
                reasoning = delta.reasoning_content
                full_response += reasoning

        # æå–è¯Šæ–­ç»“æœï¼ˆå¸¦dx:å‰ç¼€ï¼‰
        diagnosis_with_prefix = extract_diagnosis_from_response(full_response)

        # å»é™¤dx:å‰ç¼€ï¼Œç”¨äºæ¯”è¾ƒ
        diagnosis = diagnosis_with_prefix.replace('dx:', '') if diagnosis_with_prefix.startswith(
            'dx:') else diagnosis_with_prefix

        # åˆ¤æ–­è¯Šæ–­æ˜¯å¦æ­£ç¡®
        is_correct = (diagnosis == true_label) if true_label else False

        # å†™å…¥å“åº”å’Œè¯Šæ–­ç»“æœ
        with open(output_file, 'a', encoding='utf-8') as f:
            f.write(f"\nå¤§æ¨¡å‹å®Œæ•´å“åº”:\n{full_response}\n")
            f.write(f"\n{'=' * 60}\n")
            f.write(f"æå–çš„è¯Šæ–­ç»“æœ(å¸¦å‰ç¼€): {diagnosis_with_prefix}\n")
            f.write(f"ç”¨äºæ¯”è¾ƒçš„è¯Šæ–­ä»£ç : {diagnosis}\n")
            if true_label:
                f.write(f"çœŸå®æ ‡ç­¾: {true_label}\n")
                f.write(f"è¯Šæ–­æ˜¯å¦æ­£ç¡®: {'âœ… æ­£ç¡®' if is_correct else 'âŒ é”™è¯¯'}\n")
            else:
                f.write(f"çœŸå®æ ‡ç­¾: æœªæ‰¾åˆ°\n")
                f.write(f"è¯Šæ–­æ˜¯å¦æ­£ç¡®: æ— æ³•åˆ¤æ–­\n")
            f.write(f"{'=' * 60}\n")
            f.write(f"\nåˆ†æå®Œæˆ\n")
            f.write(f"æ€»å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦\n")
            f.write(f"ç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        print(
            f"âœ… [è¿›ç¨‹{process_id} PID:{pid}] å®Œæˆåˆ†æ: {image_filename} -> {diagnosis} (çœŸå®: {true_label}) {'âœ…' if is_correct else 'âŒ'}")

        return {
            "image_name": image_filename,
            "process_id": process_id,
            "pid": pid,
            "clinical_data_found": clinical_data is not None,
            "clinical_data": clinical_data,
            "true_label": true_label,  # æ–°å¢çœŸå®æ ‡ç­¾
            "predicted_label": diagnosis,  # æ–°å¢é¢„æµ‹æ ‡ç­¾ï¼ˆå»é™¤å‰ç¼€ï¼‰
            "predicted_label_with_prefix": diagnosis_with_prefix,  # æ–°å¢å¸¦å‰ç¼€çš„é¢„æµ‹æ ‡ç­¾
            "is_correct": is_correct,  # æ–°å¢æ­£ç¡®æ€§åˆ¤æ–­
            "response": full_response,
            "status": "success",
            "response_length": len(full_response),
            "output_file": str(output_file)
        }

    except Exception as e:
        with open(output_file, 'a', encoding='utf-8') as f:
            f.write(f"\nåˆ†æå¤±è´¥\n")
            f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n")
            f.write(f"{'=' * 60}\n\n")

        print(f"âŒ [è¿›ç¨‹{process_id} PID:{pid}] åˆ†æå¤±è´¥: {image_filename} - {e}")
        return {
            "image_name": image_filename,
            "process_id": process_id,
            "pid": pid,
            "clinical_data_found": False,
            "clinical_data": None,
            "true_label": None,
            "predicted_label": "error",
            "predicted_label_with_prefix": "error",
            "is_correct": False,
            "response": "",
            "status": f"error: {str(e)}",
            "response_length": 0,
            "output_file": str(output_file)
        }


def analyze_skin_images_multimodal(config_path="config.json"):
    """
    å¤šæ¨¡æ€å¤šè¿›ç¨‹æ‰¹é‡åˆ†æ
    """
    # åŠ è½½é…ç½®
    config = load_config(config_path)
    api_config = config["api_config"]
    analysis_config = config["analysis_config"]

    # åŠ è½½æ‚£è€…ä¸´åºŠæ•°æ®
    print("ğŸ“Š åŠ è½½æ‚£è€…ä¸´åºŠæ•°æ®...")
    patient_df = load_patient_data(analysis_config["csv_file_path"])

    if patient_df is None:
        print("âŒ æ— æ³•åŠ è½½æ‚£è€…æ•°æ®ï¼Œé€€å‡ºåˆ†æ")
        return [], None

    # è·å–æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    folder_path = analysis_config["folder_path"]
    supported_formats = analysis_config["supported_formats"]

    image_files = []
    for f in os.listdir(folder_path):
        file_path = Path(folder_path) / f
        if file_path.suffix.lower() in supported_formats and file_path.is_file():
            image_files.append(file_path)

    if not image_files:
        print("æœªåœ¨è¯¥æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°å›¾ç‰‡ã€‚")
        return [], patient_df

    print(f"å…±æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print(f"ä½¿ç”¨ {len(api_config['api_keys'])} ä¸ªAPIå¯†é’¥è¿›è¡Œå¤šæ¨¡æ€å¤šè¿›ç¨‹åˆ†æ...\n")

    # å‡†å¤‡ä»»åŠ¡å‚æ•°
    tasks = []
    api_keys = api_config["api_keys"]
    output_dir = "multimodel_outputs_qwen"
    image_id_column = analysis_config.get("image_id_column", "image_id")

    for i, image_path in enumerate(image_files):
        # è½®è¯¢åˆ†é…APIå¯†é’¥
        api_key = api_keys[i % len(api_keys)]
        process_id = i % len(api_keys) + 1

        task_args = (
            image_path,
            config,
            api_key,
            api_config["base_url"],
            api_config["model_type"],
            process_id,
            output_dir,
            patient_df,
            image_id_column
        )
        tasks.append(task_args)

    # ä½¿ç”¨è¿›ç¨‹æ± æ‰§è¡Œä»»åŠ¡
    max_workers = min(analysis_config.get("max_workers", 4), len(api_keys))
    results = []

    print(f"å¯åŠ¨ {max_workers} ä¸ªè¿›ç¨‹è¿›è¡Œåˆ†æ...\n")
    start_time = time.time()

    with Pool(processes=max_workers) as pool:
        results = pool.map(analyze_single_image_multimodal, tasks)

    end_time = time.time()

    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r["status"] == "success")
    clinical_data_found_count = sum(1 for r in results if r["clinical_data_found"])

    print(f"\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š æ€»å…±å¤„ç†: {len(results)} å¼ å›¾ç‰‡")
    print(f"âœ… æˆåŠŸ: {success_count} å¼ ")
    print(f"ğŸ“‹ æ‰¾åˆ°ä¸´åºŠæ•°æ®: {clinical_data_found_count} å¼ ")
    print(f"â±ï¸ æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")

    return results, patient_df


def create_multimodal_summary(results, patient_df, output_dir="multimodel_outputs_qwen"):
    """åˆ›å»ºå¤šæ¨¡æ€åˆ†ææ±‡æ€»æ–‡ä»¶ï¼ŒåŒ…å«è¯Šæ–­æ­£ç¡®æ€§åˆ†æ"""
    summary_path = Path(output_dir) / "multimodal_analysis_summary.txt"

    # è®¡ç®—å‡†ç¡®ç‡ç»Ÿè®¡
    valid_results = [r for r in results if r["status"] == "success" and r["true_label"] is not None]
    correct_results = [r for r in valid_results if r["is_correct"]]

    accuracy = len(correct_results) / len(valid_results) if valid_results else 0

    # å„ç±»åˆ«å‡†ç¡®ç‡ç»Ÿè®¡
    category_stats = {}
    for result in valid_results:
        true_label = result["true_label"]
        predicted_label = result["predicted_label"]  # ä½¿ç”¨å»é™¤å‰ç¼€çš„ç‰ˆæœ¬è¿›è¡Œæ¯”è¾ƒ
        is_correct = result["is_correct"]

        if true_label not in category_stats:
            category_stats[true_label] = {
                "total": 0,
                "correct": 0,
                "predictions": Counter()
            }

        category_stats[true_label]["total"] += 1
        category_stats[true_label]["predictions"][predicted_label] += 1

        if is_correct:
            category_stats[true_label]["correct"] += 1

    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("å¤šæ¨¡æ€çš®è‚¤å›¾åƒåˆ†ææ±‡æ€»æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")

        f.write(f"åˆ†ææ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ€»å›¾ç‰‡æ•°é‡: {len(results)}\n")

        success_count = sum(1 for r in results if r["status"] == "success")
        clinical_count = sum(1 for r in results if r["clinical_data_found"])

        f.write(f"æˆåŠŸåˆ†æ: {success_count} å¼ \n")
        f.write(f"ç»“åˆä¸´åºŠæ•°æ®: {clinical_count} å¼ \n")
        f.write(f"ä¸´åºŠæ•°æ®åŒ¹é…ç‡: {clinical_count / len(results) * 100:.1f}%\n\n")

        # å‡†ç¡®ç‡ç»Ÿè®¡
        f.write("è¯Šæ–­å‡†ç¡®ç‡ç»Ÿè®¡:\n")
        f.write("-" * 40 + "\n")
        f.write(f"å¯è¯„ä¼°å›¾ç‰‡æ•°é‡: {len(valid_results)} å¼ \n")
        f.write(f"æ­£ç¡®è¯Šæ–­æ•°é‡: {len(correct_results)} å¼ \n")
        f.write(f"æ€»ä½“å‡†ç¡®ç‡: {accuracy:.2%}\n\n")

        # å„ç±»åˆ«å‡†ç¡®ç‡
        f.write("å„ç±»åˆ«å‡†ç¡®ç‡è¯¦æƒ…:\n")
        f.write("=" * 80 + "\n")
        for true_label, stats in sorted(category_stats.items()):
            category_accuracy = stats["correct"] / stats["total"] if stats["total"] > 0 else 0
            f.write(f"\n{true_label}:\n")
            f.write(f"  æ€»æ•°: {stats['total']} å¼ \n")
            f.write(f"  æ­£ç¡®: {stats['correct']} å¼ \n")
            f.write(f"  å‡†ç¡®ç‡: {category_accuracy:.2%}\n")
            f.write(f"  é¢„æµ‹åˆ†å¸ƒ: {dict(stats['predictions'])}\n")

        # è¯¦ç»†åˆ†ææƒ…å†µ
        f.write("\nè¯¦ç»†åˆ†æç»“æœ:\n")
        f.write("=" * 80 + "\n")

        for result in results:
            status_icon = "âœ…" if result["status"] == "success" else "âŒ"
            clinical_icon = "ğŸ“‹" if result["clinical_data_found"] else "âš ï¸"

            f.write(f"\n{status_icon}{clinical_icon} {result['image_name']}\n")

            if result["status"] == "success":
                f.write(f"çœŸå®æ ‡ç­¾: {result['true_label'] if result['true_label'] else 'æœªçŸ¥'}\n")
                f.write(f"é¢„æµ‹æ ‡ç­¾: {result['predicted_label']}\n")

                if result["true_label"]:
                    correctness_icon = "âœ…" if result["is_correct"] else "âŒ"
                    f.write(f"è¯Šæ–­ç»“æœ: {correctness_icon} {'æ­£ç¡®' if result['is_correct'] else 'é”™è¯¯'}\n")
                else:
                    f.write(f"è¯Šæ–­ç»“æœ: âš ï¸ æ— æ³•åˆ¤æ–­æ­£ç¡®æ€§\n")

                if result["clinical_data_found"] and result["clinical_data"]:
                    clinical = result["clinical_data"]
                    f.write(f"ä¸´åºŠä¿¡æ¯: ")
                    if 'age' in clinical and pd.notna(clinical['age']):
                        f.write(f"å¹´é¾„{clinical['age']}å² ")
                    if 'sex' in clinical and pd.notna(clinical['sex']):
                        sex_display = "ç”·" if clinical['sex'].lower() in ['male', 'm'] else "å¥³"
                        f.write(f"{sex_display}æ€§ ")
                    if 'localization' in clinical and pd.notna(clinical['localization']):
                        loc_mapping = {'back': 'èƒŒéƒ¨', 'lower extremity': 'ä¸‹è‚¢', 'face': 'é¢éƒ¨', 'trunk': 'èº¯å¹²'}
                        loc_display = loc_mapping.get(clinical['localization'], clinical['localization'])
                        f.write(f"{loc_display}")
                    f.write("\n")

                f.write(f"å¤„ç†è¿›ç¨‹: {result['process_id']}\n")
                f.write(f"å“åº”é•¿åº¦: {result['response_length']} å­—ç¬¦\n")
            else:
                f.write(f"é”™è¯¯ä¿¡æ¯: {result['status']}\n")
            f.write("-" * 40 + "\n")

    print(f"ğŸ“‹ å¤šæ¨¡æ€åˆ†ææ±‡æ€»æ–‡ä»¶: {summary_path}")
    print(f"ğŸ“Š è¯Šæ–­å‡†ç¡®ç‡: {accuracy:.2%} ({len(correct_results)}/{len(valid_results)})")


if __name__ == "__main__":
    multiprocessing.freeze_support()

    print("ğŸš€ å¯åŠ¨å¤šæ¨¡æ€çš®è‚¤å›¾åƒåˆ†æç³»ç»Ÿ...")
    print("ğŸ“Š å°†ç»“åˆä¸´åºŠæ•°æ®å’Œå›¾åƒè¿›è¡Œç»¼åˆåˆ†æ...")
    print("ğŸ¯ å¤§æ¨¡å‹å°†åªè¾“å‡ºç—…å˜ç±»å‹ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯„ä¼°è¯Šæ–­å‡†ç¡®ç‡")

    results, patient_df = analyze_skin_images_multimodal("config.json")

    if results:
        create_multimodal_summary(results, patient_df)

    print("\nğŸ¯ æ‰€æœ‰åˆ†æä»»åŠ¡å®Œæˆï¼")