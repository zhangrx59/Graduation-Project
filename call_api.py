import os
import base64
import json
import pandas as pd
import multiprocessing
import time
import re
from pathlib import Path
from multiprocessing import Pool
from openai import OpenAI


def load_config(config_path="config.json"):
    """ä»JSONæ–‡ä»¶åŠ è½½é…ç½®"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ {config_path} æœªæ‰¾åˆ°")
        raise
    except json.JSONDecodeError:
        print(f"é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ {config_path} æ ¼å¼ä¸æ­£ç¡®")
        raise


def encode_image_to_base64(image_path):
    """å°†æœ¬åœ°å›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def load_patient_data(csv_path):
    """
    åŠ è½½æ‚£è€…ä¸´åºŠæ•°æ®
    """
    try:
        df = pd.read_csv(csv_path)
        print(f"æˆåŠŸåŠ è½½æ‚£è€…æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
        print(f"æ•°æ®åˆ—: {df.columns.tolist()}")
        return df
    except Exception as e:
        print(f"åŠ è½½æ‚£è€…æ•°æ®å¤±è´¥: {e}")
        return None


def create_multimodal_prompt(clinical_data, config):
    """
    ä»configä¸­è¯»å–æ‰€æœ‰æç¤ºè¯ç»„ä»¶ï¼Œæ„å»ºå®Œæ•´çš„å¤šæ¨¡æ€æç¤ºè¯
    """
    prompts_config = config["prompts"]

    clinical_info = ""
    if clinical_data is not None:
        clinical_info = "æ‚£è€…ä¸´åºŠä¿¡æ¯ï¼š\n"

        # å¹´é¾„
        if 'age' in clinical_data and pd.notna(clinical_data['age']):
            age = clinical_data['age']
            clinical_info += f"- å¹´é¾„: {age} å²\n"

        # æ€§åˆ«
        if 'sex' in clinical_data and pd.notna(clinical_data['sex']):
            sex = clinical_data['sex']
            sex_display = "ç”·æ€§" if sex.lower() in ['male', 'm'] else "å¥³æ€§" if sex.lower() in ['female', 'f'] else sex
            clinical_info += f"- æ€§åˆ«: {sex_display}\n"

        # ç—…å˜éƒ¨ä½
        if 'localization' in clinical_data and pd.notna(clinical_data['localization']):
            localization = clinical_data['localization']
            localization_mapping = {
                'back': 'èƒŒéƒ¨', 'lower extremity': 'ä¸‹è‚¢', 'face': 'é¢éƒ¨',
                'trunk': 'èº¯å¹²', 'chest': 'èƒ¸éƒ¨', 'unknown': 'æœªçŸ¥éƒ¨ä½',
                'upper extremity': 'ä¸Šè‚¢', 'abdomen': 'è…¹éƒ¨', 'foot': 'è¶³éƒ¨'
            }
            loc_display = localization_mapping.get(localization, localization)
            clinical_info += f"- ç—…å˜éƒ¨ä½: {loc_display}\n"

    # æ„å»ºåˆ†ææ­¥éª¤
    analysis_steps = "\n".join([f"{i + 1}. {step}" for i, step in enumerate(prompts_config["analysis_steps"])])

    # æ„å»ºç–¾ç—…ç±»åˆ«
    disease_categories = "\n".join(
        [f"- {name} ({code})" for code, name in prompts_config["disease_categories"].items()])

    # æ„å»ºå®Œæ•´æç¤ºè¯ - å¼ºè°ƒåªè¾“å‡ºç—…å˜ç±»å‹
    full_prompt = f"""{prompts_config["base_prompt"]}

{clinical_info}

è¯·åŸºäºä»¥ä¸Šä¸´åºŠä¿¡æ¯å’Œçš®è‚¤ç—…å˜å›¾åƒï¼Œè¿›è¡Œç»¼åˆåˆ†æï¼š

åˆ†ææ­¥éª¤ï¼š
{analysis_steps}

å¯é€‰è¯Šæ–­ç±»åˆ«ï¼š
{disease_categories}

{prompts_config["output_requirement"]}

é‡è¦ï¼šè¯·åªè¾“å‡ºæœ€ç»ˆçš„ç—…å˜ç±»å‹è‹±æ–‡ç¼©å†™ï¼Œä¸è¦è¾“å‡ºå…¶ä»–ä»»ä½•å†…å®¹ã€‚"""

    return full_prompt


def find_patient_data_by_image_id(patient_df, image_filename, image_id_column='image_id'):
    """
    æ ¹æ®å›¾ç‰‡æ–‡ä»¶åæŸ¥æ‰¾å¯¹åº”çš„æ‚£è€…æ•°æ®
    åªè¿”å› age, sex, localization ä¸‰åˆ—æ•°æ®ï¼Œè¿‡æ»¤æ‰dxå’Œdx_type
    """
    if patient_df is None:
        return None

    # ä»å›¾ç‰‡æ–‡ä»¶åæå–image_idï¼ˆå»æ‰æ‰©å±•åï¼‰
    image_id = Path(image_filename).stem

    # åœ¨image_idåˆ—ä¸­ç²¾ç¡®åŒ¹é…
    if image_id_column in patient_df.columns:
        match = patient_df[patient_df[image_id_column] == image_id]
        if not match.empty:
            # åªè¿”å›éœ€è¦çš„ä¸‰åˆ—æ•°æ®ï¼Œè¿‡æ»¤æ‰dxå’Œdx_type
            clinical_data = match.iloc[0][['age', 'sex', 'localization']].to_dict()
            return clinical_data

    return None


def extract_diagnosis_from_response(response_text):
    """
    ä»å¤§æ¨¡å‹å“åº”ä¸­æå–è¯Šæ–­ç»“æœ
    """
    # å®šä¹‰å¯èƒ½çš„è¯Šæ–­ç±»åˆ«
    diagnosis_codes = ['dx:akiec', 'dx:bcc', 'dx:bkl', 'dx:df', 'dx:nv', 'dx:mel', 'dx:vasc']

    # åœ¨å“åº”æ–‡æœ¬ä¸­æŸ¥æ‰¾è¯Šæ–­ä»£ç 
    for code in diagnosis_codes:
        if re.search(r'\b' + code + r'\b', response_text, re.IGNORECASE):
            return code

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„è¯Šæ–­ä»£ç ï¼Œè¿”å›æœªçŸ¥
    return "unknown"


def analyze_single_image_multimodal(args):
    """
    å•å¼ å›¾ç‰‡çš„å¤šæ¨¡æ€åˆ†æä»»åŠ¡
    å‚æ•°: (image_path, config, api_key, base_url, model_type, process_id, output_dir, patient_df, image_id_column)
    """
    image_path, config, api_key, base_url, model_type, process_id, output_dir, patient_df, image_id_column = args

    current_process = multiprocessing.current_process()
    pid = current_process.pid
    image_filename = image_path.name

    # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / f"process_{process_id}_output.txt"

    print(f"âš¡ [è¿›ç¨‹{process_id} PID:{pid}] å¼€å§‹åˆ†æ: {image_filename}")

    # æŸ¥æ‰¾æ‚£è€…ä¸´åºŠæ•°æ®ï¼ˆåªè·å– age, sex, localizationï¼‰
    clinical_data = find_patient_data_by_image_id(patient_df, image_filename, image_id_column)

    # åˆ›å»ºå¤šæ¨¡æ€æç¤ºè¯
    multimodal_prompt = create_multimodal_prompt(clinical_data, config)

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(api_key=api_key, base_url=base_url)

    # å°†å›¾åƒè½¬æ¢ä¸º base64
    base64_image = encode_image_to_base64(image_path)

    try:
        # å‘è¾“å‡ºæ–‡ä»¶å†™å…¥å¼€å§‹ä¿¡æ¯
        with open(output_file, 'a', encoding='utf-8') as f:
            f.write(f"\n{'=' * 60}\n")
            f.write(f"å›¾ç‰‡: {image_filename}\n")
            f.write(f"è¿›ç¨‹: {process_id} (PID: {pid})\n")
            f.write(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")

            if clinical_data:
                f.write(f"\næ‚£è€…ä¸´åºŠä¿¡æ¯:\n")
                if 'age' in clinical_data and pd.notna(clinical_data['age']):
                    f.write(f"  å¹´é¾„: {clinical_data['age']} å²\n")
                if 'sex' in clinical_data and pd.notna(clinical_data['sex']):
                    sex_display = "ç”·æ€§" if clinical_data['sex'].lower() in ['male', 'm'] else "å¥³æ€§" if clinical_data[
                                                                                                             'sex'].lower() in [
                                                                                                             'female',
                                                                                                             'f'] else \
                    clinical_data['sex']
                    f.write(f"  æ€§åˆ«: {sex_display}\n")
                if 'localization' in clinical_data and pd.notna(clinical_data['localization']):
                    loc_mapping = {
                        'back': 'èƒŒéƒ¨', 'lower extremity': 'ä¸‹è‚¢', 'face': 'é¢éƒ¨',
                        'trunk': 'èº¯å¹²', 'chest': 'èƒ¸éƒ¨', 'unknown': 'æœªçŸ¥éƒ¨ä½',
                        'upper extremity': 'ä¸Šè‚¢', 'abdomen': 'è…¹éƒ¨', 'foot': 'è¶³éƒ¨'
                    }
                    loc_display = loc_mapping.get(clinical_data['localization'], clinical_data['localization'])
                    f.write(f"  ç—…å˜éƒ¨ä½: {loc_display}\n")
            else:
                f.write(f"æ‚£è€…ä¸´åºŠä¿¡æ¯: æœªæ‰¾åˆ°å¯¹åº”æ•°æ®\n")

            f.write(f"{'=' * 60}\n")

        # å‘æ¨¡å‹å‘é€å¤šæ¨¡æ€è¯·æ±‚
        response = client.chat.completions.create(
            model=model_type,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": multimodal_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ],
            stream=True,
        )

        # æ”¶é›†å“åº”å†…å®¹
        full_response = ""
        for chunk in response:
            if not chunk.choices:
                continue
            delta = chunk.choices[0].delta
            if delta.content:
                content = delta.content
                full_response += content
            if hasattr(delta, "reasoning_content") and delta.reasoning_content:
                reasoning = delta.reasoning_content
                full_response += reasoning

        # æå–è¯Šæ–­ç»“æœ
        diagnosis = extract_diagnosis_from_response(full_response)

        # å†™å…¥å“åº”å’Œè¯Šæ–­ç»“æœ
        with open(output_file, 'a', encoding='utf-8') as f:
            f.write(f"\nå¤§æ¨¡å‹å®Œæ•´å“åº”:\n{full_response}\n")
            f.write(f"\n{'=' * 60}\n")
            f.write(f"æå–çš„è¯Šæ–­ç»“æœ: {diagnosis}\n")
            f.write(f"{'=' * 60}\n")
            f.write(f"\nåˆ†æå®Œæˆ\n")
            f.write(f"æ€»å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦\n")
            f.write(f"ç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        print(f"âœ… [è¿›ç¨‹{process_id} PID:{pid}] å®Œæˆåˆ†æ: {image_filename} -> {diagnosis}")

        return {
            "image_name": image_filename,
            "process_id": process_id,
            "pid": pid,
            "clinical_data_found": clinical_data is not None,
            "clinical_data": clinical_data,
            "response": full_response,
            "diagnosis": diagnosis,  # æ–°å¢è¯Šæ–­ç»“æœå­—æ®µ
            "status": "success",
            "response_length": len(full_response),
            "output_file": str(output_file)
        }

    except Exception as e:
        with open(output_file, 'a', encoding='utf-8') as f:
            f.write(f"\nåˆ†æå¤±è´¥\n")
            f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n")
            f.write(f"{'=' * 60}\n\n")

        print(f"âŒ [è¿›ç¨‹{process_id} PID:{pid}] åˆ†æå¤±è´¥: {image_filename} - {e}")
        return {
            "image_name": image_filename,
            "process_id": process_id,
            "pid": pid,
            "clinical_data_found": False,
            "clinical_data": None,
            "response": "",
            "diagnosis": "error",  # é”™è¯¯çŠ¶æ€
            "status": f"error: {str(e)}",
            "response_length": 0,
            "output_file": str(output_file)
        }


def analyze_skin_images_multimodal(config_path="config.json"):
    """
    å¤šæ¨¡æ€å¤šè¿›ç¨‹æ‰¹é‡åˆ†æ
    """
    # åŠ è½½é…ç½®
    config = load_config(config_path)
    api_config = config["api_config"]
    analysis_config = config["analysis_config"]

    # åŠ è½½æ‚£è€…ä¸´åºŠæ•°æ®
    print("ğŸ“Š åŠ è½½æ‚£è€…ä¸´åºŠæ•°æ®...")
    patient_df = load_patient_data(analysis_config["csv_file_path"])

    if patient_df is None:
        print("âŒ æ— æ³•åŠ è½½æ‚£è€…æ•°æ®ï¼Œé€€å‡ºåˆ†æ")
        return [], None

    # è·å–æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    folder_path = analysis_config["folder_path"]
    supported_formats = analysis_config["supported_formats"]

    image_files = []
    for f in os.listdir(folder_path):
        file_path = Path(folder_path) / f
        if file_path.suffix.lower() in supported_formats and file_path.is_file():
            image_files.append(file_path)

    if not image_files:
        print("æœªåœ¨è¯¥æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°å›¾ç‰‡ã€‚")
        return [], patient_df

    print(f"å…±æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print(f"ä½¿ç”¨ {len(api_config['api_keys'])} ä¸ªAPIå¯†é’¥è¿›è¡Œå¤šæ¨¡æ€å¤šè¿›ç¨‹åˆ†æ...\n")

    # å‡†å¤‡ä»»åŠ¡å‚æ•°
    tasks = []
    api_keys = api_config["api_keys"]
    output_dir = "multimodal_outputs"
    image_id_column = analysis_config.get("image_id_column", "image_id")

    for i, image_path in enumerate(image_files):
        # è½®è¯¢åˆ†é…APIå¯†é’¥
        api_key = api_keys[i % len(api_keys)]
        process_id = i % len(api_keys) + 1

        task_args = (
            image_path,
            config,
            api_key,
            api_config["base_url"],
            api_config["model_type"],
            process_id,
            output_dir,
            patient_df,
            image_id_column
        )
        tasks.append(task_args)

    # ä½¿ç”¨è¿›ç¨‹æ± æ‰§è¡Œä»»åŠ¡
    max_workers = min(analysis_config.get("max_workers", 4), len(api_keys))
    results = []

    print(f"å¯åŠ¨ {max_workers} ä¸ªè¿›ç¨‹è¿›è¡Œåˆ†æ...\n")
    start_time = time.time()

    with Pool(processes=max_workers) as pool:
        results = pool.map(analyze_single_image_multimodal, tasks)

    end_time = time.time()

    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r["status"] == "success")
    clinical_data_found_count = sum(1 for r in results if r["clinical_data_found"])

    print(f"\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š æ€»å…±å¤„ç†: {len(results)} å¼ å›¾ç‰‡")
    print(f"âœ… æˆåŠŸ: {success_count} å¼ ")
    print(f"ğŸ“‹ æ‰¾åˆ°ä¸´åºŠæ•°æ®: {clinical_data_found_count} å¼ ")
    print(f"â±ï¸ æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")

    return results, patient_df


def create_multimodal_summary(results, patient_df, output_dir="multimodal_outputs"):
    """åˆ›å»ºå¤šæ¨¡æ€åˆ†ææ±‡æ€»æ–‡ä»¶ï¼ŒåŒ…å«æ¯å¼ å›¾ç‰‡çš„è¯Šæ–­ç»“æœ"""
    summary_path = Path(output_dir) / "multimodal_analysis_summary.txt"

    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("å¤šæ¨¡æ€çš®è‚¤å›¾åƒåˆ†ææ±‡æ€»æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")

        f.write(f"åˆ†ææ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ€»å›¾ç‰‡æ•°é‡: {len(results)}\n")

        success_count = sum(1 for r in results if r["status"] == "success")
        clinical_count = sum(1 for r in results if r["clinical_data_found"])

        f.write(f"æˆåŠŸåˆ†æ: {success_count} å¼ \n")
        f.write(f"ç»“åˆä¸´åºŠæ•°æ®: {clinical_count} å¼ \n")
        f.write(f"ä¸´åºŠæ•°æ®åŒ¹é…ç‡: {clinical_count / len(results) * 100:.1f}%\n\n")

        # è¯Šæ–­ç»“æœç»Ÿè®¡
        diagnosis_stats = {}
        for result in results:
            if result["status"] == "success":
                diagnosis = result["diagnosis"]
                diagnosis_stats[diagnosis] = diagnosis_stats.get(diagnosis, 0) + 1

        f.write("è¯Šæ–­ç»“æœç»Ÿè®¡:\n")
        f.write("-" * 40 + "\n")
        for diagnosis, count in sorted(diagnosis_stats.items()):
            f.write(f"{diagnosis}: {count} å¼ \n")
        f.write("\n")

        # è¯¦ç»†åˆ†ææƒ…å†µ - åŒ…å«æ¯å¼ å›¾ç‰‡çš„è¯Šæ–­ç»“æœ
        f.write("è¯¦ç»†åˆ†æç»“æœ:\n")
        f.write("=" * 80 + "\n")

        for result in results:
            status_icon = "âœ…" if result["status"] == "success" else "âŒ"
            clinical_icon = "ğŸ“‹" if result["clinical_data_found"] else "âš ï¸"

            f.write(f"\n{status_icon}{clinical_icon} {result['image_name']}\n")
            f.write(f"è¯Šæ–­ç»“æœ: {result['diagnosis']}\n")

            if result["clinical_data_found"] and result["clinical_data"]:
                clinical = result["clinical_data"]
                f.write(f"ä¸´åºŠä¿¡æ¯: ")
                if 'age' in clinical and pd.notna(clinical['age']):
                    f.write(f"å¹´é¾„{clinical['age']}å² ")
                if 'sex' in clinical and pd.notna(clinical['sex']):
                    sex_display = "ç”·" if clinical['sex'].lower() in ['male', 'm'] else "å¥³"
                    f.write(f"{sex_display}æ€§ ")
                if 'localization' in clinical and pd.notna(clinical['localization']):
                    loc_mapping = {'back': 'èƒŒéƒ¨', 'lower extremity': 'ä¸‹è‚¢', 'face': 'é¢éƒ¨', 'trunk': 'èº¯å¹²'}
                    loc_display = loc_mapping.get(clinical['localization'], clinical['localization'])
                    f.write(f"{loc_display}")
                f.write("\n")

            f.write(f"å¤„ç†è¿›ç¨‹: {result['process_id']}\n")
            if result["status"] == "success":
                f.write(f"å“åº”é•¿åº¦: {result['response_length']} å­—ç¬¦\n")
            else:
                f.write(f"é”™è¯¯ä¿¡æ¯: {result['status']}\n")
            f.write("-" * 40 + "\n")

    print(f"ğŸ“‹ å¤šæ¨¡æ€åˆ†ææ±‡æ€»æ–‡ä»¶: {summary_path}")


if __name__ == "__main__":
    multiprocessing.freeze_support()

    print("ğŸš€ å¯åŠ¨å¤šæ¨¡æ€çš®è‚¤å›¾åƒåˆ†æç³»ç»Ÿ...")
    print("ğŸ“Š å°†ç»“åˆä¸´åºŠæ•°æ®å’Œå›¾åƒè¿›è¡Œç»¼åˆåˆ†æ...")
    print("ğŸ¯ å¤§æ¨¡å‹å°†åªè¾“å‡ºç—…å˜ç±»å‹ï¼Œæ±‡æ€»æ–‡ä»¶å°†åŒ…å«æ‰€æœ‰è¯Šæ–­ç»“æœ")

    results, patient_df = analyze_skin_images_multimodal("config.json")

    if results:
        create_multimodal_summary(results, patient_df)

    print("\nğŸ¯ æ‰€æœ‰åˆ†æä»»åŠ¡å®Œæˆï¼")