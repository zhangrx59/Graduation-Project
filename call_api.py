import os
import base64
import json
import threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from openai import OpenAI


def load_config(config_path="config.json"):
    """ä»JSONæ–‡ä»¶åŠ è½½é…ç½®"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ {config_path} æœªæ‰¾åˆ°")
        raise
    except json.JSONDecodeError:
        print(f"é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ {config_path} æ ¼å¼ä¸æ­£ç¡®")
        raise


def encode_image_to_base64(image_path):
    """å°†æœ¬åœ°å›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


class ThreadOutputManager:
    """çº¿ç¨‹è¾“å‡ºç®¡ç†å™¨ï¼Œæ¯ä¸ªçº¿ç¨‹æœ‰ç‹¬ç«‹çš„è¾“å‡ºæ–‡ä»¶"""

    def __init__(self, output_dir="thread_outputs"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.thread_files = {}
        self.lock = threading.Lock()

    def get_thread_file(self, thread_id):
        """è·å–çº¿ç¨‹å¯¹åº”çš„è¾“å‡ºæ–‡ä»¶"""
        with self.lock:
            if thread_id not in self.thread_files:
                filename = self.output_dir / f"thread_{thread_id}_output.txt"
                self.thread_files[thread_id] = open(filename, 'w', encoding='utf-8')
                print(f"ğŸ“„ åˆ›å»ºçº¿ç¨‹ {thread_id} çš„è¾“å‡ºæ–‡ä»¶: {filename}")
            return self.thread_files[thread_id]

    def write_to_thread(self, thread_id, content):
        """å‘æŒ‡å®šçº¿ç¨‹çš„è¾“å‡ºæ–‡ä»¶å†™å…¥å†…å®¹"""
        file_obj = self.get_thread_file(thread_id)
        with self.lock:
            file_obj.write(content)
            file_obj.flush()

    def close_all(self):
        """å…³é—­æ‰€æœ‰æ–‡ä»¶"""
        for file_obj in self.thread_files.values():
            file_obj.close()
        print("âœ… æ‰€æœ‰çº¿ç¨‹è¾“å‡ºæ–‡ä»¶å·²å…³é—­")


def analyze_single_image(args):
    """
    å•ä¸ªå›¾ç‰‡åˆ†æä»»åŠ¡
    å‚æ•°: (image_path, prompt, api_key, base_url, model_type, thread_id, output_manager)
    """
    image_path, prompt, api_key, base_url, model_type, thread_id, output_manager = args

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(api_key=api_key, base_url=base_url)

    # å°†å›¾åƒè½¬æ¢ä¸º base64
    base64_image = encode_image_to_base64(image_path)

    # åœ¨æ§åˆ¶å°åªæ˜¾ç¤ºè¿›åº¦ï¼Œä¸æ˜¾ç¤ºå¤§æ¨¡å‹è¾“å‡º
    print(f"ğŸ§µ [çº¿ç¨‹{thread_id}] å¼€å§‹åˆ†æ: {image_path.name}")

    try:
        # å‘è¾“å‡ºæ–‡ä»¶å†™å…¥å¼€å§‹ä¿¡æ¯
        start_msg = f"\n{'=' * 60}\n"
        start_msg += f"ğŸ–¼ï¸ å›¾ç‰‡: {image_path.name}\n"
        start_msg += f"ğŸ§µ çº¿ç¨‹: {thread_id}\n"
        start_msg += f"{'=' * 60}\n"
        output_manager.write_to_thread(thread_id, start_msg)

        # å‘æ¨¡å‹å‘é€è¯·æ±‚
        response = client.chat.completions.create(
            model=model_type,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ],
            stream=True,
        )

        # æ”¶é›†å“åº”å†…å®¹ï¼Œåªå†™å…¥æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
        full_response = ""
        for chunk in response:
            if not chunk.choices:
                continue
            delta = chunk.choices[0].delta
            if delta.content:
                content = delta.content
                full_response += content
                # åªå†™å…¥æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
                output_manager.write_to_thread(thread_id, content)
            if hasattr(delta, "reasoning_content") and delta.reasoning_content:
                reasoning = delta.reasoning_content
                full_response += reasoning
                # åªå†™å…¥æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
                output_manager.write_to_thread(thread_id, reasoning)

        # å†™å…¥ç»“æŸä¿¡æ¯
        end_msg = f"\n\nâœ… åˆ†æå®Œæˆ\n"
        end_msg += f"ğŸ“ æ€»å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦\n"
        end_msg += f"{'=' * 60}\n\n"
        output_manager.write_to_thread(thread_id, end_msg)

        print(f"âœ… [çº¿ç¨‹{thread_id}] å®Œæˆ: {image_path.name}")

        return {
            "image_name": image_path.name,
            "thread_id": thread_id,
            "response": full_response,
            "status": "success",
            "response_length": len(full_response)
        }

    except Exception as e:
        error_msg = f"\nâŒ åˆ†æå¤±è´¥\n"
        error_msg += f"é”™è¯¯ä¿¡æ¯: {str(e)}\n"
        error_msg += f"{'=' * 60}\n\n"
        output_manager.write_to_thread(thread_id, error_msg)

        print(f"âŒ [çº¿ç¨‹{thread_id}] åˆ†æå¤±è´¥: {image_path.name} - {e}")
        return {
            "image_name": image_path.name,
            "thread_id": thread_id,
            "response": "",
            "status": f"error: {str(e)}",
            "response_length": 0
        }


def analyze_skin_images_multithread(config_path="config.json"):
    """
    å¤šçº¿ç¨‹æ‰¹é‡åˆ†ææ–‡ä»¶å¤¹ä¸­çš„çš®è‚¤å›¾åƒ
    """
    # åŠ è½½é…ç½®
    config = load_config(config_path)
    api_config = config["api_config"]
    analysis_config = config["analysis_config"]

    # åˆå§‹åŒ–è¾“å‡ºç®¡ç†å™¨
    output_manager = ThreadOutputManager("thread_outputs")

    try:
        # è·å–æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        folder_path = analysis_config["folder_path"]
        supported_formats = analysis_config["supported_formats"]

        image_files = []
        for f in os.listdir(folder_path):
            file_path = Path(folder_path) / f
            if file_path.suffix.lower() in supported_formats and file_path.is_file():
                image_files.append(file_path)

        if not image_files:
            print("æœªåœ¨è¯¥æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°å›¾ç‰‡ã€‚")
            return []

        print(f"å…±æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        print(f"ä½¿ç”¨ {len(api_config['api_keys'])} ä¸ªAPIå¯†é’¥è¿›è¡Œå¤šçº¿ç¨‹åˆ†æ...")
        print(f"å¤§æ¨¡å‹è¾“å‡ºå°†ä¿å­˜åˆ°ç‹¬ç«‹çš„txtæ–‡ä»¶ä¸­ï¼ˆæ§åˆ¶å°ä¸æ˜¾ç¤ºï¼‰...\n")

        # å‡†å¤‡ä»»åŠ¡å‚æ•°
        tasks = []
        api_keys = api_config["api_keys"]

        for i, image_path in enumerate(image_files):
            # è½®è¯¢åˆ†é…APIå¯†é’¥
            api_key = api_keys[i % len(api_keys)]
            thread_id = i % len(api_keys) + 1  # çº¿ç¨‹IDä»1å¼€å§‹

            task_args = (
                image_path,
                analysis_config["prompt"],
                api_key,
                api_config["base_url"],
                api_config["model_type"],
                thread_id,
                output_manager
            )
            tasks.append(task_args)

        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä»»åŠ¡
        max_workers = min(analysis_config.get("max_workers", 4), len(api_keys))
        results = []

        print(f"å¯åŠ¨ {max_workers} ä¸ªçº¿ç¨‹è¿›è¡Œåˆ†æ...\n")

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {executor.submit(analyze_single_image, task): task for task in tasks}

            for future in future_to_task:
                result = future.result()
                results.append(result)

        # æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶ä¿¡æ¯
        print(f"\nğŸ“ çº¿ç¨‹è¾“å‡ºæ–‡ä»¶:")
        for thread_id in range(1, max_workers + 1):
            output_file = Path("thread_outputs") / f"thread_{thread_id}_output.txt"
            if output_file.exists():
                # ç»Ÿè®¡è¯¥çº¿ç¨‹å¤„ç†çš„å›¾ç‰‡æ•°é‡
                thread_images = [r for r in results if r["thread_id"] == thread_id]
                success_count = sum(1 for r in thread_images if r["status"] == "success")
                file_size = output_file.stat().st_size
                print(f"  çº¿ç¨‹ {thread_id}: {output_file}")
                print(f"     å¤„ç†å›¾ç‰‡: {len(thread_images)} å¼ , æˆåŠŸ: {success_count} å¼ ")
                print(f"     æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")

        # ç»Ÿè®¡æ€»ä½“ç»“æœ
        success_count = sum(1 for r in results if r["status"] == "success")
        error_count = len(results) - success_count

        print(f"\nğŸ‰ æ‰€æœ‰å›¾ç‰‡åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š æ€»å…±å¤„ç†: {len(results)} å¼ å›¾ç‰‡")
        print(f"âœ… æˆåŠŸ: {success_count} å¼ ")
        print(f"âŒ å¤±è´¥: {error_count} å¼ ")

        return results

    finally:
        # ç¡®ä¿å…³é—­æ‰€æœ‰æ–‡ä»¶
        output_manager.close_all()


def create_summary_file(results, output_dir="thread_outputs"):
    """åˆ›å»ºæ±‡æ€»æ–‡ä»¶ï¼Œæ˜¾ç¤ºæ¯ä¸ªçº¿ç¨‹å¤„ç†çš„å›¾ç‰‡"""
    summary_path = Path(output_dir) / "thread_summary.txt"
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("å¤šçº¿ç¨‹çš®è‚¤å›¾åƒåˆ†ææ±‡æ€»\n")
        f.write("=" * 50 + "\n\n")

        # æŒ‰çº¿ç¨‹åˆ†ç»„
        thread_images = {}
        for result in results:
            thread_id = result["thread_id"]
            if thread_id not in thread_images:
                thread_images[thread_id] = []
            thread_images[thread_id].append({
                "image_name": result["image_name"],
                "status": result["status"],
                "response_length": result.get("response_length", 0)
            })

        for thread_id, images in sorted(thread_images.items()):
            f.write(f"çº¿ç¨‹ {thread_id} å¤„ç†çš„å›¾ç‰‡ ({len(images)} å¼ ):\n")
            for img_info in images:
                status_icon = "âœ…" if img_info["status"] == "success" else "âŒ"
                f.write(f"  {status_icon} {img_info['image_name']}")
                if img_info["status"] == "success":
                    f.write(f" ({img_info['response_length']} å­—ç¬¦)")
                f.write(f" - {img_info['status']}\n")
            f.write("\n")

        # æ€»ä½“ç»Ÿè®¡
        total_success = sum(1 for r in results if r["status"] == "success")
        f.write(f"æ€»ä½“ç»Ÿè®¡: {total_success}/{len(results)} æˆåŠŸ\n")

    print(f"ğŸ“‹ çº¿ç¨‹æ±‡æ€»æ–‡ä»¶: {summary_path}")


if __name__ == "__main__":
    # === ä½¿ç”¨å¤šçº¿ç¨‹æ‰§è¡Œæ‰¹é‡åˆ†æ ===
    results = analyze_skin_images_multithread("config.json")

    # åˆ›å»ºæ±‡æ€»æ–‡ä»¶
    if results:
        create_summary_file(results)

    print("\nğŸ¯ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")