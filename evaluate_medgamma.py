# evaluate_medgamma_lora.py
# -*- coding: utf-8 -*-

import os
import re
import warnings

import torch
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

from transformers import AutoModelForImageTextToText, AutoProcessor
from peft import PeftModel

from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_curve,
    auc,
    precision_recall_curve,
    average_precision_score,
)
from sklearn.preprocessing import label_binarize


# ========== è·¯å¾„ & é…ç½®ï¼ˆéœ€ä¸å¾®è°ƒè„šæœ¬ä¸€è‡´ï¼‰ ==========

# åŸºç¡€æ¨¡å‹
BASE_MODEL = "google/medgemma-4b-it"

# åŸå§‹ metadata CSVï¼ˆå’Œå¾®è°ƒç”¨çš„æ˜¯åŒä¸€ä¸ªï¼‰
METADATA_CSV = r"C:\Users\zhangrx59\PycharmProjects\LoRA\metadata_isic_with_shape.csv"

# å¾®è°ƒè„šæœ¬ prepare_splits() ç”Ÿæˆçš„ test CSV
TEST_CSV = METADATA_CSV.replace(".csv", "_test_5cls.csv")

# LoRA é€‚é…å™¨è¾“å‡ºç›®å½•ï¼ˆå¾®è°ƒè„šæœ¬é‡Œç”¨çš„ OUTPUT_DIRï¼‰
LORA_DIR = r"C:\Users\zhangrx59\PycharmProjects\LoRA\medgemma_lora_derm_from_metadata"

# å›¾åƒæ ¹ç›®å½•å’Œåç¼€
IMAGE_ROOT_DIR = r"C:\Users\zhangrx59\PycharmProjects\LoRA\ISIC_dataset"
IMAGE_EXT = ".png"   # å¦‚æœæ˜¯ .jpg å°±æ”¹æˆ ".jpg"

# è¯„ä¼°å›¾åƒä¿å­˜ç›®å½•ï¼ˆLoRA ç»“æœå•ç‹¬æ”¾ä¸€ä¸ªç›®å½•ï¼‰
PLOTS_DIR = r"C:\Users\zhangrx59\PycharmProjects\LoRA\lora_eval"
os.makedirs(PLOTS_DIR, exist_ok=True)

# æ‰¹å¤§å°
BATCH_SIZE = 32

# åˆ—åï¼ˆä¸å¾®è°ƒè„šæœ¬ä¿æŒä¸€è‡´ï¼‰
COL_IMAGE_ID    = "image_id"
COL_AGE         = "å¹´é¾„"
COL_SEX         = "æ€§åˆ«"
COL_FATHER_ORI  = "çˆ¶ç±è´¯"
COL_MOTHER_ORI  = "æ¯ç±è´¯"
COL_BIOPSY      = "æ˜¯å¦æ´»æ£€"
COL_SMOKE       = "æ˜¯å¦å¸çƒŸ"
COL_DRINK       = "æ˜¯å¦é¥®é…’"
COL_PESTICIDE   = "å†œè¯"
COL_SKIN_CANCER = "çš®è‚¤ç™Œç—…å²"
COL_OTHER_CA    = "ç™Œç—‡ç—…å²"
COL_TAP_WATER   = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰è‡ªæ¥æ°´"
COL_SEWER       = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰ä¸‹æ°´é“"
COL_PHOTOTYPE   = "çš®è‚¤å…‰å‹"
COL_REGION      = "åŒºåŸŸ"
COL_D1          = "ç›´å¾„1"
COL_D2          = "ç›´å¾„2"
COL_PRURITUS    = "ç˜™ç—’"
COL_GROWTH      = "æ˜¯å¦é•¿å¤§"
COL_PAIN        = "ç–¼ç—›"
COL_MORPH_CHANGE= "å½¢æ€å˜åŒ–"
COL_BLEEDING    = "å‡ºè¡€"
COL_ELEVATED    = "æ˜¯å¦éš†èµ·"

# çš®è‚¤ç—…åˆ†ç±»æ ‡ç­¾åˆ—ï¼ˆå’Œå¾®è°ƒæ—¶ä¸€è‡´ï¼‰
COL_TARGET      = "dx"

# åªè¯„ä¼°è¿™ 5 ç±»ï¼ˆä½ ç°åœ¨çš„å®éªŒè®¾å®šï¼‰
ALLOWED_DX = ["akiec", "bcc", "bkl", "nev", "mel"]


# ========== ä¸€äº›å·¥å…·å‡½æ•° ==========

def yn_str(v, yes="æœ‰", no="æ— ", unk="ä¸è¯¦"):
    if isinstance(v, str):
        vs = v.strip().upper()
        if vs in ["TRUE", "T", "YES", "Y"]:
            return yes
        if vs in ["FALSE", "F", "NO", "N"]:
            return no
        if vs in ["UNK", "UNKNOWN", "NA", "NAN", "NONE", ""]:
            return unk
    if isinstance(v, (bool, int)):
        return yes if bool(v) else no
    if v != v:  # NaN
        return unk
    return str(v)


def build_clinical_note(row: pd.Series) -> str:
    age = row.get(COL_AGE, "")
    sex = str(row.get(COL_SEX, "") or "").strip()
    region = str(row.get(COL_REGION, "") or "").strip()
    father_ori = str(row.get(COL_FATHER_ORI, "") or "").strip()
    mother_ori = str(row.get(COL_MOTHER_ORI, "") or "").strip()

    skin_ca = yn_str(row.get(COL_SKIN_CANCER))
    other_ca = yn_str(row.get(COL_OTHER_CA))
    smoke = yn_str(row.get(COL_SMOKE), yes="å¸çƒŸ", no="ä¸å¸çƒŸ")
    drink = yn_str(row.get(COL_DRINK), yes="é¥®é…’", no="ä¸é¥®é…’")
    pesticide = yn_str(row.get(COL_PESTICIDE), yes="æœ‰å†œè¯æ¥è§¦å²", no="æ— å†œè¯æ¥è§¦å²")

    tap = yn_str(row.get(COL_TAP_WATER), yes="æœ‰è‡ªæ¥æ°´", no="æ— è‡ªæ¥æ°´")
    sewer = yn_str(row.get(COL_SEWER), yes="æœ‰ä¸‹æ°´é“", no="æ— ä¸‹æ°´é“")

    phototype = row.get(COL_PHOTOTYPE, "")
    d1 = row.get(COL_D1, "")
    d2 = row.get(COL_D2, "")

    pruritus = yn_str(row.get(COL_PRURITUS))
    growth = yn_str(row.get(COL_GROWTH))
    pain = yn_str(row.get(COL_PAIN))
    morph_change = yn_str(row.get(COL_MORPH_CHANGE))
    bleeding = yn_str(row.get(COL_BLEEDING))
    elevated = yn_str(row.get(COL_ELEVATED))

    # æ€§åˆ«æ±‰åŒ–
    if isinstance(sex, str) and sex.upper() in ["MALE", "M"]:
        sex_cn = "ç”·æ€§"
    elif isinstance(sex, str) and sex.upper() in ["FEMALE", "F"]:
        sex_cn = "å¥³æ€§"
    else:
        sex_cn = sex or "æ€§åˆ«ä¸è¯¦"

    region_cn = region or "éƒ¨ä½ä¸è¯¦"

    size_str = ""
    if d1 and d2:
        size_str = f"çš®æŸçº¦ {d1}Ã—{d2} mm"
    elif d1:
        size_str = f"çš®æŸæœ€å¤§å¾„çº¦ {d1} mm"

    photo_str = f"çš®è‚¤å…‰å‹ï¼š{phototype} å‹" if phototype != "" else ""

    origin_str = ""
    if father_ori or mother_ori:
        origin_str = f"çˆ¶ç±è´¯ï¼š{father_ori}ï¼Œæ¯ç±è´¯ï¼š{mother_ori}ã€‚"

    parts = []
    parts.append(f"{age}å²{sex_cn}ï¼Œ{region_cn}çš®è‚¤ç—…å˜ã€‚")
    if size_str:
        parts.append(size_str + "ã€‚")
    if origin_str:
        parts.append(origin_str)

    parts.append(f"æ—¢å¾€çš®è‚¤ç™Œç—…å²ï¼š{skin_ca}ï¼›å…¶ä»–æ¶æ€§è‚¿ç˜¤ç—…å²ï¼š{other_ca}ã€‚")
    parts.append(f"ç”Ÿæ´»æ–¹å¼ï¼š{smoke}ï¼Œ{drink}ï¼Œ{pesticide}ã€‚")
    parts.append(f"å±…ä½ç¯å¢ƒï¼š{tap}ï¼Œ{sewer}ã€‚")
    if photo_str:
        parts.append(photo_str + "ã€‚")

    parts.append(
        f"ç—‡çŠ¶ä½“å¾ï¼šç˜™ç—’{pruritus}ï¼Œæ˜¯å¦é•¿å¤§{growth}ï¼Œç–¼ç—›{pain}ï¼Œ"
        f"å½¢æ€å˜åŒ–{morph_change}ï¼Œå‡ºè¡€{bleeding}ï¼Œéš†èµ·{elevated}ã€‚"
    )

    return "".join(parts)


def normalize_dx(label: str) -> str:
    if not isinstance(label, str):
        return ""
    s = label.strip().lower()
    if s == "nv":
        s = "nev"
    return s


def extract_dx_code(text: str) -> str:
    """
    ä»æ¨¡å‹è¾“å‡ºæ–‡æœ¬ä¸­æå– 5 ç±» dx codeï¼š
    - æ”¯æŒ nv/nevï¼Œç»Ÿä¸€æˆ nev
    """
    if not isinstance(text, str):
        return "unknown"
    text_lower = text.lower()
    m = re.search(r"\b(akiec|bcc|bkl|nev|nv|mel)\b", text_lower)
    if not m:
        return "unknown"
    code = m.group(1)
    code = normalize_dx(code)
    return code if code in ALLOWED_DX else "unknown"


# ========== åŠ è½½ LoRA å¾®è°ƒåçš„æ¨¡å‹ ==========

def load_lora_model_and_processor():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")

    print("ğŸ”§ åŠ è½½ MedGEMMA åŸºç¡€æ¨¡å‹ ...")
    base_model = AutoModelForImageTextToText.from_pretrained(
        BASE_MODEL,
        dtype=torch.bfloat16 if device.type == "cuda" else torch.float32,
    ).to(device)

    print(f"ğŸ”§ ä» {LORA_DIR} åŠ è½½ LoRA é€‚é…å™¨ ...")
    model = PeftModel.from_pretrained(base_model, LORA_DIR)
    model.eval()

    # processor ä» LoRA ç›®å½•åŠ è½½ï¼Œä¿è¯ tokenizer é…ç½®ä¸€è‡´
    processor = AutoProcessor.from_pretrained(LORA_DIR)
    processor.tokenizer.padding_side = "right"

    return model, processor, device


# ========== ä½¿ç”¨ Test é›†è¯„ä¼° LoRA æ¨¡å‹ï¼ˆæ‰¹é‡ï¼‰ ==========

def evaluate_lora_on_test():
    if not os.path.exists(TEST_CSV):
        raise FileNotFoundError(
            f"æœªæ‰¾åˆ°æµ‹è¯•é›† CSV: {TEST_CSV}\n"
            f"è¯·å…ˆè¿è¡Œå¾®è°ƒè„šæœ¬ç”Ÿæˆ *_test_5cls.csvã€‚"
        )

    df = pd.read_csv(TEST_CSV, encoding="utf-8")
    print(f"ğŸ“„ ä» Test CSV è¯»å– {len(df)} æ¡æ ·æœ¬: {TEST_CSV}")

    if COL_IMAGE_ID not in df.columns or COL_TARGET not in df.columns:
        raise ValueError("TEST_CSV ä¸­ç¼ºå°‘ image_id æˆ– dx åˆ—")

    model, processor, device = load_lora_model_and_processor()

    y_true, y_pred = [], []
    total, correct = 0, 0
    missing_image = 0

    for idx, row in df.iterrows():
        image_id = str(row[COL_IMAGE_ID])
        label_raw = normalize_dx(str(row[COL_TARGET]))

        if label_raw not in ALLOWED_DX:
            continue

        img_path = os.path.join(IMAGE_ROOT_DIR, image_id + IMAGE_EXT)
        if not os.path.exists(img_path):
            print(f"âš  image_id={image_id} å¯¹åº”å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
            missing_image += 1
            continue

        try:
            image = Image.open(img_path).convert("RGB")
        except Exception as e:
            print(f"âš  æ‰“å¼€å›¾ç‰‡å¤±è´¥ image_id={image_id}: {e}")
            missing_image += 1
            continue

        clinical_note = build_clinical_note(row)

        messages = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "You are a dermatology assistant. "
                            "Given the clinical note and the skin lesion image, "
                            "your task is to classify the skin lesion into one of the following dx codes: "
                            "akiec, bcc, bkl, nev, mel. "
                            "Always answer with exactly one lowercase code "
                            "(akiec/bcc/bkl/nev/mel), no explanations."
                        ),
                    }
                ],
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "ä¸´åºŠç—…å†æ‘˜è¦å¦‚ä¸‹ï¼š\n"
                            f"{clinical_note}\n\n"
                            "è¯·ç»“åˆç—…å†å’Œä¸‹æ–¹çš„çš®è‚¤ç—…å˜å›¾åƒï¼Œåˆ¤æ–­è¯¥ç—…å˜æœ€å¯èƒ½å±äºå“ªä¸€ç±»ï¼Œ"
                            "å¹¶åªè¾“å‡ºä¸€ä¸ªè‹±æ–‡å°å†™ dx ä»£ç ï¼ˆakiec/bcc/bkl/nev/melï¼‰ï¼Œ"
                            "ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å­—ç¬¦ï¼š"
                        ),
                    },
                    {"type": "image", "image": image},
                ],
            },
        ]

        prompt_text = processor.apply_chat_template(
            messages,
            add_generation_prompt=True,
            tokenize=False,
        )

        inputs = processor(
            text=[prompt_text],
            images=[image],
            return_tensors="pt",
        ).to(device)

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=8,
                do_sample=False,
            )

        input_len = inputs["input_ids"].shape[1]
        gen_ids = outputs[:, input_len:]
        gen_text = processor.batch_decode(gen_ids, skip_special_tokens=True)[0]
        pred_label = extract_dx_code(gen_text)

        total += 1
        if pred_label == label_raw:
            correct += 1

        y_true.append(label_raw)
        y_pred.append(pred_label)

        print(
            f"ğŸ©º [{total}] image_id={image_id} | pred={pred_label} | true={label_raw} "
            f"| {'âœ…' if pred_label == label_raw else 'âŒ'} | raw={gen_text!r}"
        )

    print("\n====== ğŸ“Š LoRA æ¨¡å‹åœ¨ Test é›†ä¸Šçš„è¯„ä¼°ç»“æœï¼ˆé€æ¡ï¼‰ ======")
    print(f"æœ‰æ•ˆæ ·æœ¬æ•°: {total}")
    print(f"ç¼ºå°‘å›¾ç‰‡æ ·æœ¬æ•°: {missing_image}")
    if total > 0:
        print(f"æ€»ä½“å‡†ç¡®ç‡: {correct/total:.2%}")

    # ï¼ˆå…¶ä½™éƒ¨åˆ†ä¸å˜ï¼šæ··æ·†çŸ©é˜µ / ROC / PR å›¾ç”Ÿæˆï¼‰
    # ...

    else:
        print("æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬")
        return

    # ===== æŒ‡æ ‡ + æ··æ·†çŸ©é˜µ + ROC/PR æ›²çº¿ =====
    classes = ALLOWED_DX
    y_true_arr = np.array(y_true)
    y_pred_arr = np.array(y_pred)

    print("\n====== ğŸ“Š classification_report ======")
    print(classification_report(y_true_arr, y_pred_arr, labels=classes))

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true_arr, y_pred_arr, labels=classes)
    print("\n====== ğŸ“Š æ··æ·†çŸ©é˜µï¼ˆrows=true, cols=predï¼‰ ======")
    print(classes)
    print(cm)

    fig_cm, ax_cm = plt.subplots(figsize=(6, 5))
    im = ax_cm.imshow(cm, interpolation="nearest", cmap=plt.cm.Blues)
    fig_cm.colorbar(im, ax=ax_cm)
    ax_cm.set_xticks(range(len(classes)))
    ax_cm.set_yticks(range(len(classes)))
    ax_cm.set_xticklabels(classes)
    ax_cm.set_yticklabels(classes)
    ax_cm.set_xlabel("Predicted label")
    ax_cm.set_ylabel("True label")
    ax_cm.set_title("Confusion Matrix (LoRA, 5 classes, batch)")
    plt.setp(ax_cm.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")

    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax_cm.text(
                j, i, str(cm[i, j]),
                ha="center", va="center",
                color="white" if cm[i, j] > thresh else "black",
            )

    fig_cm.tight_layout()
    cm_path = os.path.join(PLOTS_DIR, "confusion_matrix_lora.png")
    fig_cm.savefig(cm_path, dpi=300)
    plt.close(fig_cm)
    print(f"ğŸ“ æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜åˆ°: {cm_path}")

    # ROC & PRï¼ˆç”¨ one-hot é¢„æµ‹å½“ä½œ score è¿‘ä¼¼ï¼‰
    y_true_bin = label_binarize(y_true_arr, classes=classes)
    scores = np.zeros_like(y_true_bin, dtype=float)
    for i, pred in enumerate(y_pred_arr):
        if pred in classes:
            j = classes.index(pred)
            scores[i, j] = 1.0

    # ROC
    fig_roc, ax_roc = plt.subplots(figsize=(6, 5))
    for idx, cls in enumerate(classes):
        try:
            fpr, tpr, _ = roc_curve(y_true_bin[:, idx], scores[:, idx])
            roc_auc = auc(fpr, tpr)
            ax_roc.plot(fpr, tpr, label=f"{cls} (AUC={roc_auc:.2f})")
        except ValueError:
            continue

    ax_roc.plot([0, 1], [0, 1], "k--", label="chance")
    ax_roc.set_xlim([0.0, 1.0])
    ax_roc.set_ylim([0.0, 1.05])
    ax_roc.set_xlabel("False Positive Rate")
    ax_roc.set_ylabel("True Positive Rate")
    ax_roc.set_title("ROC Curves (LoRA, 5 classes, batch, pseudo-scores)")
    ax_roc.legend(loc="lower right", fontsize=8)
    fig_roc.tight_layout()
    roc_path = os.path.join(PLOTS_DIR, "roc_curve_lora.png")
    fig_roc.savefig(roc_path, dpi=300)
    plt.close(fig_roc)
    print(f"ğŸ“ ROC æ›²çº¿å›¾å·²ä¿å­˜åˆ°: {roc_path}")

    # PR
    fig_pr, ax_pr = plt.subplots(figsize=(6, 5))
    for idx, cls in enumerate(classes):
        try:
            precision, recall, _ = precision_recall_curve(
                y_true_bin[:, idx], scores[:, idx]
            )
            ap = average_precision_score(y_true_bin[:, idx], scores[:, idx])
            ax_pr.plot(recall, precision, label=f"{cls} (AP={ap:.2f})")
        except ValueError:
            continue

    ax_pr.set_xlim([0.0, 1.0])
    ax_pr.set_ylim([0.0, 1.05])
    ax_pr.set_xlabel("Recall")
    ax_pr.set_ylabel("Precision")
    ax_pr.set_title("Precision-Recall Curves (LoRA, 5 classes, batch, pseudo-scores)")
    ax_pr.legend(loc="lower left", fontsize=8)
    fig_pr.tight_layout()
    pr_path = os.path.join(PLOTS_DIR, "pr_curve_lora.png")
    fig_pr.savefig(pr_path, dpi=300)
    plt.close(fig_pr)
    print(f"ğŸ“ P-R æ›²çº¿å›¾å·²ä¿å­˜åˆ°: {pr_path}")


if __name__ == "__main__":
    warnings.filterwarnings("once")
    evaluate_lora_on_test()
