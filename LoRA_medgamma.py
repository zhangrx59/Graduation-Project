# finetune_medgemma_lora_from_metadata.py
# -*- coding: utf-8 -*-

import os
from dataclasses import dataclass
from typing import Dict, Any

import torch
from torch.utils.data import Dataset
from PIL import Image

from datasets import load_dataset
from transformers import (
    AutoModelForImageTextToText,
    AutoProcessor,
    TrainingArguments,
    Trainer,
)
from peft import (
    LoraConfig,
    get_peft_model,
)


# ===================== 0. é…ç½®åŒºåŸŸï¼šä½ éœ€è¦æ”¹çš„åœ°æ–¹ =====================

# åŸºç¡€æ¨¡å‹
BASE_MODEL = "google/medgemma-4b-it"

# ä½ çš„ metadata CSVï¼ˆå°±æ˜¯ metadata_isic_with_shape.csvï¼‰
METADATA_CSV = r"C:\Users\zhangrx59\PycharmProjects\LoRA\metadata_isic_with_shape.csv"

# å›¾ç‰‡æ‰€åœ¨æ ¹ç›®å½• + åç¼€
IMAGE_ROOT_DIR = r"C:\Users\zhangrx59\PycharmProjects\LoRA\ISIC_dataset"
IMAGE_EXT = ".png"   # æ ¹æ®å®é™…æ”¹æˆ ".jpg" æˆ– ".png"

# CSV ä¸­åˆ—åï¼ˆæ¥è‡ªä½ è¡¨ï¼‰
COL_IMAGE_ID    = "image_id"
COL_AGE         = "å¹´é¾„"
COL_SEX         = "æ€§åˆ«"
COL_FATHER_ORI  = "çˆ¶ç±è´¯"
COL_MOTHER_ORI  = "æ¯ç±è´¯"
COL_BIOPSY      = "æ˜¯å¦æ´»æ£€"
COL_SMOKE       = "æ˜¯å¦å¸çƒŸ"
COL_DRINK       = "æ˜¯å¦é¥®é…’"
COL_PESTICIDE   = "å†œè¯"
COL_SKIN_CANCER = "çš®è‚¤ç™Œç—…å²"
COL_OTHER_CA    = "ç™Œç—‡ç—…å²"
COL_TAP_WATER   = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰è‡ªæ¥æ°´"
COL_SEWER       = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰ä¸‹æ°´é“"
COL_PHOTOTYPE   = "çš®è‚¤å…‰å‹"
COL_REGION      = "åŒºåŸŸ"
COL_D1          = "ç›´å¾„1"
COL_D2          = "ç›´å¾„2"
COL_PRURITUS    = "ç˜™ç—’"
COL_GROWTH      = "æ˜¯å¦é•¿å¤§"
COL_PAIN        = "ç–¼ç—›"
COL_MORPH_CHANGE= "å½¢æ€å˜åŒ–"
COL_BLEEDING    = "å‡ºè¡€"
COL_ELEVATED    = "æ˜¯å¦éš†èµ·"

# ç›®æ ‡è¾“å‡ºåˆ—ï¼šçš®è‚¤ç—…åˆ†ç±»æ ‡ç­¾ï¼ˆå¦‚ akiec/bcc/bkl/df/nv/mel/vascï¼‰
# å¦‚æœä½  CSV é‡Œæ˜¯ä¸­æ–‡åˆ—åï¼Œæ¯”å¦‚â€œè¯Šæ–­æ ‡ç­¾â€ï¼Œå°±æ”¹æˆ "è¯Šæ–­æ ‡ç­¾"
COL_TARGET      = "dx"

# LoRA adapter è¾“å‡ºç›®å½•ï¼ˆè°ƒå¥½çš„æ¨¡å‹å°±ä¿å­˜åœ¨è¿™é‡Œï¼‰
OUTPUT_DIR = r"C:\Users\zhangrx59\PycharmProjects\LoRA\medgemma_lora_derm_from_metadata"


# ===================== 1. æŠŠå¤šåˆ—ç—…å†ä¿¡æ¯ -> ä¸€æ®µä¸­æ–‡ç—…å†æ‘˜è¦ =====================

def yn_str(v, yes="æœ‰", no="æ— ", unk="ä¸è¯¦"):
    """
    æŠŠ True/False/'TRUE'/'FALSE'/'UNK'/NaN ç»Ÿä¸€è½¬æˆä¸­æ–‡ â€œæœ‰/æ— /ä¸è¯¦â€
    """
    if isinstance(v, str):
        vs = v.strip().upper()
        if vs in ["TRUE", "T", "YES", "Y"]:
            return yes
        if vs in ["FALSE", "F", "NO", "N"]:
            return no
        if vs in ["UNK", "UNKNOWN", "NA", "NAN", "NONE", ""]:
            return unk
    if isinstance(v, (bool, int)):
        return yes if bool(v) else no
    if v != v:  # NaN
        return unk
    return str(v)


def build_clinical_note(row) -> str:
    """
    æ ¹æ®è¡¨ä¸­çš„å¤šåˆ—å­—æ®µï¼Œè‡ªåŠ¨æ‹¼æ¥æˆä¸€æ®µä¸­æ–‡ç—…å†æ‘˜è¦æ–‡æœ¬ã€‚
    """
    age = row.get(COL_AGE, "")
    sex = str(row.get(COL_SEX, "") or "").strip()
    region = str(row.get(COL_REGION, "") or "").strip()
    father_ori = str(row.get(COL_FATHER_ORI, "") or "").strip()
    mother_ori = str(row.get(COL_MOTHER_ORI, "") or "").strip()

    skin_ca = yn_str(row.get(COL_SKIN_CANCER))
    other_ca = yn_str(row.get(COL_OTHER_CA))
    smoke = yn_str(row.get(COL_SMOKE), yes="å¸çƒŸ", no="ä¸å¸çƒŸ")
    drink = yn_str(row.get(COL_DRINK), yes="é¥®é…’", no="ä¸é¥®é…’")
    pesticide = yn_str(row.get(COL_PESTICIDE), yes="æœ‰å†œè¯æ¥è§¦å²", no="æ— å†œè¯æ¥è§¦å²")

    tap = yn_str(row.get(COL_TAP_WATER), yes="æœ‰è‡ªæ¥æ°´", no="æ— è‡ªæ¥æ°´")
    sewer = yn_str(row.get(COL_SEWER), yes="æœ‰ä¸‹æ°´é“", no="æ— ä¸‹æ°´é“")

    phototype = row.get(COL_PHOTOTYPE, "")
    d1 = row.get(COL_D1, "")
    d2 = row.get(COL_D2, "")

    pruritus = yn_str(row.get(COL_PRURITUS))
    growth = yn_str(row.get(COL_GROWTH))
    pain = yn_str(row.get(COL_PAIN))
    morph_change = yn_str(row.get(COL_MORPH_CHANGE))
    bleeding = yn_str(row.get(COL_BLEEDING))
    elevated = yn_str(row.get(COL_ELEVATED))

    # æ€§åˆ«æ±‰åŒ–
    if isinstance(sex, str) and sex.upper() in ["MALE", "M"]:
        sex_cn = "ç”·æ€§"
    elif isinstance(sex, str) and sex.upper() in ["FEMALE", "F"]:
        sex_cn = "å¥³æ€§"
    else:
        sex_cn = sex or "æ€§åˆ«ä¸è¯¦"

    # éƒ¨ä½
    region_cn = region or "éƒ¨ä½ä¸è¯¦"

    # ç›´å¾„
    size_str = ""
    if d1 and d2:
        size_str = f"çš®æŸçº¦ {d1}Ã—{d2} mm"
    elif d1:
        size_str = f"çš®æŸæœ€å¤§å¾„çº¦ {d1} mm"

    # çš®è‚¤å…‰å‹
    photo_str = f"çš®è‚¤å…‰å‹ï¼š{phototype} å‹" if phototype != "" else ""

    # å‡ºèº«åœ°
    origin_str = ""
    if father_ori or mother_ori:
        origin_str = f"çˆ¶ç±è´¯ï¼š{father_ori}ï¼Œæ¯ç±è´¯ï¼š{mother_ori}ã€‚"

    parts = []

    parts.append(f"{age}å²{sex_cn}ï¼Œ{region_cn}çš®è‚¤ç—…å˜ã€‚")
    if size_str:
        parts.append(size_str + "ã€‚")
    if origin_str:
        parts.append(origin_str)

    parts.append(f"æ—¢å¾€çš®è‚¤ç™Œç—…å²ï¼š{skin_ca}ï¼›å…¶ä»–æ¶æ€§è‚¿ç˜¤ç—…å²ï¼š{other_ca}ã€‚")
    parts.append(f"ç”Ÿæ´»æ–¹å¼ï¼š{smoke}ï¼Œ{drink}ï¼Œ{pesticide}ã€‚")
    parts.append(f"å±…ä½ç¯å¢ƒï¼š{tap}ï¼Œ{sewer}ã€‚")
    if photo_str:
        parts.append(photo_str + "ã€‚")

    parts.append(
        f"ç—‡çŠ¶ä½“å¾ï¼šç˜™ç—’{pruritus}ï¼Œæ˜¯å¦é•¿å¤§{growth}ï¼Œç–¼ç—›{pain}ï¼Œå½¢æ€å˜åŒ–{morph_change}ï¼Œå‡ºè¡€{bleeding}ï¼Œéš†èµ·{elevated}ã€‚"
    )

    note = "".join(parts)
    return note


# ===================== 2. æ•°æ®é›†å®šä¹‰ï¼šæ ¹æ®ç—…ä¾‹ + å›¾åƒå­¦ä¹ åˆ†ç±» =====================

class DermMetadataDataset(Dataset):
    """
    åŸºäº metadata_isic_with_shape.csv çš„ Datasetï¼š
    - image: ç”± å›¾ç‰‡ID + IMAGE_ROOT_DIR + IMAGE_EXT æ‹¼è·¯å¾„
    - clinical_note: ç”±å¤šåˆ—å­—æ®µè‡ªåŠ¨æ‹¼æ¥
    - target_text: çš®è‚¤ç—…åˆ†ç±»æ ‡ç­¾ï¼ˆå¦‚ akiec/bcc/bkl/df/nv/mel/vascï¼‰ï¼Œä½œä¸ºç”Ÿæˆç›®æ ‡
    """
    def __init__(self, hf_dataset):
        self.ds = hf_dataset

    def __len__(self):
        return len(self.ds)

    def __getitem__(self, idx):
        row = self.ds[idx]

        image_id = str(row[COL_IMAGE_ID])
        image_path = os.path.join(IMAGE_ROOT_DIR, image_id + IMAGE_EXT)
        image = Image.open(image_path).convert("RGB")

        clinical_note = build_clinical_note(row)
        # æ ‡ç­¾ç»Ÿä¸€æˆå°å†™å­—ç¬¦ä¸²
        target_text = str(row[COL_TARGET]).strip().lower()

        # æ„é€ å¤šæ¨¡æ€å¯¹è¯ï¼š
        # systemï¼šå‘Šè¯‰æ¨¡å‹è¿™æ˜¯åˆ†ç±»ä»»åŠ¡ï¼Œåªè¾“å‡ºä¸€ä¸ªä»£ç 
        # userï¼šç»™å‡ºä¸­æ–‡ç—…å†æ‘˜è¦ + å›¾ç‰‡
        messages = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "You are a dermatology assistant. "
                            "Given the clinical note and the skin lesion image, "
                            "your task is to classify the skin lesion into one of the following dx codes: "
                            "akiec, bcc, bkl, df, nv, mel, vasc. "
                            "Only output ONE code (akiec/bcc/bkl/df/nv/mel/vasc) as the final answer. "
                            "Do NOT output any other words or explanations."
                        ),
                    }
                ],
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "ä¸´åºŠç—…å†æ‘˜è¦å¦‚ä¸‹ï¼š\n"
                            f"{clinical_note}\n\n"
                            "è¯·ç»“åˆç—…å†å’Œä¸‹æ–¹çš„çš®è‚¤ç—…å˜å›¾åƒï¼Œåˆ¤æ–­è¯¥ç—…å˜æœ€å¯èƒ½å±äºå“ªä¸€ç±»ï¼Œ"
                            "å¹¶åªè¾“å‡ºä¸€ä¸ª dx ä»£ç ï¼ˆakiec/bcc/bkl/df/nv/mel/vascï¼‰ä½œä¸ºç­”æ¡ˆï¼š"
                        ),
                    },
                    {"type": "image", "image": image},
                ],
            },
        ]

        return {
            "messages": messages,
            "image": image,
            "target_text": target_text,
        }


# ===================== 3. collatorï¼šç”¨ AutoProcessor ç»Ÿä¸€æ‰“åŒ…å¤šæ¨¡æ€ =====================

@dataclass
class MedGemmaCollator:
    processor: AutoProcessor

    def __call__(self, batch) -> Dict[str, Any]:
        # è¿™é‡Œä¾èµ– batch é‡Œçš„ 'image' / 'messages' / 'target_text'
        images = [eg["image"] for eg in batch]
        messages_list = [eg["messages"] for eg in batch]
        targets = [eg["target_text"] for eg in batch]

        texts = []
        for msgs, tgt in zip(messages_list, targets):
            # æŠŠå¤šè½®å¯¹è¯ messages å±•å¼€æˆä¸€æ®µ chat æ–‡æœ¬
            chat_text = self.processor.apply_chat_template(
                msgs,
                add_generation_prompt=False,
                tokenize=False,
            )
            # ç›´æ¥æŠŠæ ‡ç­¾ä»£ç æ‹¼åœ¨åé¢ï¼Œä½œä¸ºâ€œæ­£ç¡®å›ç­”â€
            full_text = chat_text + tgt
            texts.append(full_text)

        model_inputs = self.processor(
            text=texts,
            images=images,
            padding=True,
            truncation=True,
            return_tensors="pt",
        )

        labels = model_inputs["input_ids"].clone()
        labels[labels == self.processor.tokenizer.pad_token_id] = -100
        model_inputs["labels"] = labels
        return model_inputs


# ===================== 4. åŠ è½½æ¨¡å‹ + LoRAï¼ˆä¸ä½¿ç”¨ bitsandbytesï¼Œbf16/FP16 å…¨ç²¾ï¼‰ =====================

def load_model_and_processor():
    print("ğŸ”§ åŠ è½½ MedGemma åŸºç¡€æ¨¡å‹ï¼ˆbf16 + LoRAï¼Œå…¨ç²¾æƒé‡ï¼Œä¸ç”¨bitsandbytesï¼‰...")
    model = AutoModelForImageTextToText.from_pretrained(
        BASE_MODEL,
        dtype=torch.bfloat16,   # å¦‚æœæŠ¥ bf16 ä¸æ”¯æŒï¼Œå°±æ”¹æˆ torch.float16
        device_map="auto",
    )

    processor = AutoProcessor.from_pretrained(BASE_MODEL)
    processor.tokenizer.padding_side = "right"

    # å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆèŠ‚çœæ˜¾å­˜ï¼Œå¯é€‰ï¼‰
    model.gradient_checkpointing_enable()
    if hasattr(model, "config"):
        model.config.use_cache = False

    lora_config = LoraConfig(
        r=16,
        lora_alpha=16,
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM",
        target_modules="all-linear",
    )

    # è®©æ¨¡å‹è¾“å…¥éœ€è¦ gradï¼Œè¿™æ · LoRA å±‚èƒ½æ­£å¸¸è®­ç»ƒ
    model.enable_input_require_grads()

    # æŒ‚è½½ LoRA é€‚é…å™¨
    model = get_peft_model(model, lora_config)

    trainable, total = 0, 0
    for _, p in model.named_parameters():
        total += p.numel()
        if p.requires_grad:
            trainable += p.numel()
    print(f"ğŸ“Š æ€»å‚æ•°: {total/1e6:.1f}M, å¯è®­ç»ƒ(LoRA): {trainable/1e6:.1f}M")

    return model, processor


# ===================== 5. ä¸»è®­ç»ƒå…¥å£ =====================

def main():
    # 1) è¯»å– csv åˆ° HF Dataset
    raw = load_dataset("csv", data_files={"train": METADATA_CSV})["train"]

    # ç„¶åå†è‡ªå·±åš train/val åˆ’åˆ†
    split = raw.train_test_split(test_size=0.1, seed=42)
    train_hf = split["train"]
    val_hf = split["test"]

    train_ds = DermMetadataDataset(train_hf)
    val_ds = DermMetadataDataset(val_hf)

    model, processor = load_model_and_processor()
    collator = MedGemmaCollator(processor=processor)

    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        num_train_epochs=2,
        per_device_train_batch_size=1,
        per_device_eval_batch_size=1,
        gradient_accumulation_steps=8,
        learning_rate=1e-4,
        logging_steps=10,
        save_steps=200,
        save_total_limit=2,
        bf16=True,        # å¦‚æœ GPU ä¸æ”¯æŒ bf16ï¼Œå°±æ”¹æˆï¼šbf16=False, fp16=True
        fp16=False,
        report_to="none",  # ç‰ˆæœ¬ä¸æ”¯æŒçš„è¯å¯ä»¥æ”¹æˆ []
        remove_unused_columns=False,  # â˜† å…³é”®ï¼šä¸è¦è‡ªåŠ¨åˆ æ‰ 'image' / 'messages'
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_ds,
        eval_dataset=val_ds,   # å…ˆæ”¾åœ¨è¿™ï¼Œå°†æ¥å¯ä»¥æ‰‹åŠ¨ trainer.evaluate()
        data_collator=collator,
    )

    trainer.train()

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    model.save_pretrained(OUTPUT_DIR)
    processor.save_pretrained(OUTPUT_DIR)
    print(f"âœ… LoRA adapter å·²ä¿å­˜åˆ°: {OUTPUT_DIR}")


if __name__ == "__main__":
    main()
