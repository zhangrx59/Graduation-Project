# LoRA_medgamma_finetune.py
# -*- coding: utf-8 -*-

import os
from dataclasses import dataclass
from typing import Dict, Any, Tuple

import torch
from torch.utils.data import Dataset
from PIL import Image

import pandas as pd
from datasets import load_dataset
from sklearn.model_selection import train_test_split

from transformers import (
    AutoModelForImageTextToText,
    AutoProcessor,
    TrainingArguments,
    Trainer,
)
from peft import (
    LoraConfig,
    get_peft_model,
)

# ===================== 0. é…ç½®åŒºåŸŸ =====================

# åŸºç¡€æ¨¡å‹
BASE_MODEL = "google/medgemma-4b-it"

# åŸå§‹ metadata CSVï¼ˆåŒ…å«æ‰€æœ‰æ ·æœ¬ï¼‰
METADATA_CSV = r"C:\Users\zhangrx59\PycharmProjects\LoRA\metadata_isic_with_shape.csv"

# å›¾ç‰‡æ‰€åœ¨æ ¹ç›®å½• + åç¼€
IMAGE_ROOT_DIR = r"C:\Users\zhangrx59\PycharmProjects\LoRA\ISIC_dataset"
IMAGE_EXT = ".png"   # å¦‚æœæ˜¯ .jpg å°±æ”¹æˆ ".jpg"

# è¾“å‡ºçš„åˆ’åˆ†å CSV
TRAIN_CSV = METADATA_CSV.replace(".csv", "_train_5cls.csv")
VAL_CSV   = METADATA_CSV.replace(".csv", "_val_5cls.csv")
TEST_CSV  = METADATA_CSV.replace(".csv", "_test_5cls.csv")   # ç”¨äºåç»­ baseline / LoRA è¯„ä¼°

# åˆ—åï¼ˆä¸ä½ çš„æ•°æ®ä¸€è‡´ï¼‰
COL_IMAGE_ID    = "image_id"
COL_AGE         = "å¹´é¾„"
COL_SEX         = "æ€§åˆ«"
COL_FATHER_ORI  = "çˆ¶ç±è´¯"
COL_MOTHER_ORI  = "æ¯ç±è´¯"
COL_BIOPSY      = "æ˜¯å¦æ´»æ£€"
COL_SMOKE       = "æ˜¯å¦å¸çƒŸ"
COL_DRINK       = "æ˜¯å¦é¥®é…’"
COL_PESTICIDE   = "å†œè¯"
COL_SKIN_CANCER = "çš®è‚¤ç™Œç—…å²"
COL_OTHER_CA    = "ç™Œç—‡ç—…å²"
COL_TAP_WATER   = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰è‡ªæ¥æ°´"
COL_SEWER       = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰ä¸‹æ°´é“"
COL_PHOTOTYPE   = "çš®è‚¤å…‰å‹"
COL_REGION      = "åŒºåŸŸ"
COL_D1          = "ç›´å¾„1"
COL_D2          = "ç›´å¾„2"
COL_PRURITUS    = "ç˜™ç—’"
COL_GROWTH      = "æ˜¯å¦é•¿å¤§"
COL_PAIN        = "ç–¼ç—›"
COL_MORPH_CHANGE= "å½¢æ€å˜åŒ–"
COL_BLEEDING    = "å‡ºè¡€"
COL_ELEVATED    = "æ˜¯å¦éš†èµ·"

# çš®è‚¤ç—…åˆ†ç±»æ ‡ç­¾åˆ—ï¼ˆdx / è¯Šæ–­æ ‡ç­¾ ç­‰ï¼‰
COL_TARGET      = "dx"

# åªä¿ç•™è¿™ 5 ç±»
ALLOWED_DX = ["akiec", "bcc", "bkl", "nev", "mel"]

# LoRA adapter è¾“å‡ºç›®å½•ï¼ˆè°ƒå¥½çš„å¤§æ¨¡å‹å°±ä¿å­˜åœ¨è¿™é‡Œï¼‰
OUTPUT_DIR = r"C:\Users\zhangrx59\PycharmProjects\LoRA\medgemma_lora_derm_from_metadata"


# ===================== 1. å·¥å…·å‡½æ•°ï¼šç—…å†æ‘˜è¦æ‹¼æ¥ï¼ˆè‹±æ–‡ï¼‰ =====================

def yn_str(v, yes="yes", no="no", unk="unknown"):
    """
    ç»Ÿä¸€æŠŠå„ç§ True/False/UNK/NaN ç­‰æ˜ å°„åˆ°è‹±æ–‡ yes/no/unknown.
    """
    if isinstance(v, str):
        vs = v.strip().upper()
        if vs in ["TRUE", "T", "YES", "Y", "1"]:
            return yes
        if vs in ["FALSE", "F", "NO", "N", "0"]:
            return no
        if vs in ["UNK", "UNKNOWN", "NA", "NAN", "NONE", ""]:
            return unk
    if isinstance(v, (bool, int)):
        return yes if bool(v) else no
    if v != v:  # NaN
        return unk
    return str(v)


def build_clinical_note(row) -> str:
    """
    æ ¹æ®å¤šåˆ—å­—æ®µè‡ªåŠ¨æ‹¼æ¥æˆä¸€æ®µè‹±æ–‡ç—…å†æ‘˜è¦æ–‡æœ¬ã€‚
    å°½é‡ç¬¦åˆè‹±æ–‡åŒ»å­¦è®°å½•çš„é£æ ¼ã€‚
    """
    age = row.get(COL_AGE, "")
    sex_raw = str(row.get(COL_SEX, "") or "").strip().lower()
    region = str(row.get(COL_REGION, "") or "").strip()
    father_ori = str(row.get(COL_FATHER_ORI, "") or "").strip()
    mother_ori = str(row.get(COL_MOTHER_ORI, "") or "").strip()

    # æ€§åˆ«è‹±æ–‡åŒ–
    if sex_raw in ["ç”·", "male", "m"]:
        sex_en = "male"
    elif sex_raw in ["å¥³", "female", "f"]:
        sex_en = "female"
    else:
        sex_en = "unknown sex"

    # ç—…å² / ç”Ÿæ´»æ–¹å¼ / ç¯å¢ƒ
    skin_ca = yn_str(row.get(COL_SKIN_CANCER))
    other_ca = yn_str(row.get(COL_OTHER_CA))
    smoke = yn_str(row.get(COL_SMOKE), yes="smoker", no="non-smoker", unk="unknown smoking status")
    drink = yn_str(row.get(COL_DRINK), yes="drinker", no="non-drinker", unk="unknown drinking status")
    pesticide = yn_str(
        row.get(COL_PESTICIDE),
        yes="pesticide exposure",
        no="no pesticide exposure",
        unk="unknown pesticide exposure"
    )

    tap = yn_str(row.get(COL_TAP_WATER), yes="has tap water", no="no tap water", unk="unknown tap water supply")
    sewer = yn_str(row.get(COL_SEWER), yes="has sewerage", no="no sewerage", unk="unknown sewerage")

    phototype = row.get(COL_PHOTOTYPE, "")
    d1 = row.get(COL_D1, "")
    d2 = row.get(COL_D2, "")

    # ç—‡çŠ¶ç±»ï¼Œç»Ÿä¸€æˆ present/absent/unknownï¼ˆelevation å•ç‹¬å†™æˆ raised/flat/unknownï¼‰
    pruritus = yn_str(row.get(COL_PRURITUS), yes="present", no="absent", unk="unknown")
    growth = yn_str(row.get(COL_GROWTH), yes="present", no="absent", unk="unknown")
    pain = yn_str(row.get(COL_PAIN), yes="present", no="absent", unk="unknown")
    morph_change = yn_str(row.get(COL_MORPH_CHANGE), yes="present", no="absent", unk="unknown")
    bleeding = yn_str(row.get(COL_BLEEDING), yes="present", no="absent", unk="unknown")
    elevated = yn_str(row.get(COL_ELEVATED), yes="raised", no="flat", unk="unknown")

    # éƒ¨ä½
    region_en = region if region else "unknown location"

    # çš®æŸå¤§å°
    size_str = ""
    if d1 and d2:
        size_str = f"Lesion size approximately {d1}Ã—{d2} mm."
    elif d1:
        size_str = f"Lesion largest diameter approximately {d1} mm."

    # å…‰å‹
    photo_str = f"Skin phototype: {phototype}." if phototype != "" else ""

    # å‡ºç”Ÿåœ°
    origin_str = ""
    if father_ori or mother_ori:
        origin_str = (
            f"Father's birthplace: {father_ori or 'unknown'}, "
            f"mother's birthplace: {mother_ori or 'unknown'}."
        )

    parts = []

    # åŸºæœ¬ä¿¡æ¯
    parts.append(f"{age}-year-old {sex_en} with a skin lesion located on {region_en}.")
    if size_str:
        parts.append(size_str)
    if origin_str:
        parts.append(origin_str)

    # ç—…å²
    parts.append(f"History of skin cancer: {skin_ca}; other cancer history: {other_ca}.")

    # ç”Ÿæ´»æ–¹å¼ + ç¯å¢ƒ
    parts.append(f"Lifestyle: {smoke}, {drink}, {pesticide}.")
    parts.append(f"Living condition: {tap}, {sewer}.")
    if photo_str:
        parts.append(photo_str)

    # ç—‡çŠ¶ä½“å¾
    parts.append(
        f"Symptoms: itching {pruritus}, pain {pain}, growth {growth}, "
        f"shape change {morph_change}, bleeding {bleeding}, elevation {elevated}."
    )

    # æ‹¼æˆä¸€æ®µè‹±æ–‡
    note = " ".join(parts)
    return note


def normalize_dx(label: str) -> str:
    if not isinstance(label, str):
        return ""
    s = label.strip().lower()
    if s == "nv":
        s = "nev"
    return s


# ===================== 2. æŒ‰ç±»åˆ«å‡åŒ€åˆ’åˆ† train/val/test =====================

def prepare_splits(
    seed: int = 42,
    train_ratio: float = 0.7,
    val_ratio: float = 0.15,
    test_ratio: float = 0.15,
) -> Tuple[str, str, str]:
    """
    ä» METADATA_CSV ä¸­ï¼š
    - ä»…ä¿ç•™ dx âˆˆ ALLOWED_DX çš„æ ·æœ¬
    - æŒ‰ç±»åˆ« stratify åˆ’åˆ† train/val/testï¼ˆç›®å‰æŒ‰å›¾ç‰‡çº§åˆ«åˆ†å±‚ï¼‰
    - ä¿å­˜åˆ° *_train_5cls.csv / *_val_5cls.csv / *_test_5cls.csv
    """
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6

    if os.path.exists(TRAIN_CSV) and os.path.exists(VAL_CSV) and os.path.exists(TEST_CSV):
        print("ğŸ“ å‘ç°å·²æœ‰åˆ’åˆ†æ–‡ä»¶ï¼Œç›´æ¥å¤ç”¨ï¼š")
        print(f"  train: {TRAIN_CSV}")
        print(f"  val  : {VAL_CSV}")
        print(f"  test : {TEST_CSV}")
        return TRAIN_CSV, VAL_CSV, TEST_CSV

    print(f"ğŸ“„ è¯»å–åŸå§‹ CSV: {METADATA_CSV}")
    df = pd.read_csv(METADATA_CSV, encoding="utf-8")

    if COL_TARGET not in df.columns:
        raise ValueError(f"CSV ä¸­æ‰¾ä¸åˆ°æ ‡ç­¾åˆ— {COL_TARGET!r}")

    # å½’ä¸€åŒ– dx
    df["dx"] = df[COL_TARGET].apply(normalize_dx)
    df = df[df["dx"].isin(ALLOWED_DX)].copy()

    print(f"âœ… è¿‡æ»¤ååªä¿ç•™ {ALLOWED_DX}ï¼Œå‰©ä½™æ ·æœ¬æ•°: {len(df)}")

    # æŒ‰ dx åˆ†å±‚åˆ’åˆ† train / (val+test)
    df_train, df_tmp = train_test_split(
        df,
        test_size=val_ratio + test_ratio,
        stratify=df["dx"],
        random_state=seed,
    )

    # å†æŠŠ tmp åˆ†æˆ val/test
    tmp_ratio = test_ratio / (val_ratio + test_ratio)
    df_val, df_test = train_test_split(
        df_tmp,
        test_size=tmp_ratio,
        stratify=df_tmp["dx"],
        random_state=seed,
    )

    print("ğŸ“Š æŒ‰ç±»åˆ«åˆ†å±‚åˆ’åˆ†å®Œæˆï¼š")
    print("  train:", df_train["dx"].value_counts().to_dict())
    print("  val  :", df_val["dx"].value_counts().to_dict())
    print("  test :", df_test["dx"].value_counts().to_dict())

    # ä¿å­˜
    df_train.to_csv(TRAIN_CSV, index=False, encoding="utf-8-sig")
    df_val.to_csv(VAL_CSV, index=False, encoding="utf-8-sig")
    df_test.to_csv(TEST_CSV, index=False, encoding="utf-8-sig")

    print("ğŸ’¾ å·²ä¿å­˜åˆ’åˆ†æ–‡ä»¶ï¼š")
    print(f"  train â†’ {TRAIN_CSV}")
    print(f"  val   â†’ {VAL_CSV}")
    print(f"  test  â†’ {TEST_CSV}")

    return TRAIN_CSV, VAL_CSV, TEST_CSV


# ===================== 3. Datasetï¼šç—…ä¾‹ + å›¾åƒ â†’ åˆ†ç±»æ ‡ç­¾ =====================

class DermMetadataDataset(Dataset):
    """
    åŸºäºåˆ’åˆ†åçš„ CSV çš„ Datasetï¼š
    - image: ç”± å›¾ç‰‡ID + IMAGE_ROOT_DIR + IMAGE_EXT æ‹¼è·¯å¾„
    - clinical_note: ç”±å¤šåˆ—å­—æ®µè‡ªåŠ¨æ‹¼æ¥æˆè‹±æ–‡æ‘˜è¦
    - target_text: çš®è‚¤ç—…åˆ†ç±»æ ‡ç­¾ï¼ˆakiec/bcc/bkl/nev/melï¼‰ï¼Œä½œä¸ºç”Ÿæˆç›®æ ‡
    """
    def __init__(self, hf_dataset):
        self.ds = hf_dataset

    def __len__(self):
        return len(self.ds)

    def __getitem__(self, idx):
        row = self.ds[idx]

        image_id = str(row[COL_IMAGE_ID])
        image_path = os.path.join(IMAGE_ROOT_DIR, image_id + IMAGE_EXT)
        image = Image.open(image_path).convert("RGB")

        clinical_note = build_clinical_note(row)
        # æ ‡ç­¾ç»Ÿä¸€æˆå°å†™å­—ç¬¦ä¸²
        target_text = normalize_dx(str(row[COL_TARGET]))

        # å¤šæ¨¡æ€å¯¹è¯ Promptï¼ˆè‹±æ–‡ï¼‰
        messages = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "You are a medical image classifier for skin lesion diagnosis.\n"
                            "You must classify the lesion into exactly one of the following classes:\n"
                            "akiec, bcc, bkl, nev, mel.\n"
                            "Rules:\n"
                            "1. Only output one class name.\n"
                            "2. Do not output probability, explanation, or any extra texts.\n"
                            "3. The answer must be exactly one of: akiec, bcc, bkl, nev, mel.\n"
                        )
                    }
                ]
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            f"Clinical note:\n{clinical_note}\n\n"
                            "Based on the clinical note and the provided skin lesion image,\n"
                            "predict the most likely disease class.\n"
                            "Answer with only one class name:\n"
                            "akiec, bcc, bkl, nev, mel."
                        )
                    },
                    {"type": "image", "image": image}
                ]
            }
        ]

        return {
            "messages": messages,
            "image": image,
            "target_text": target_text,
        }


# ===================== 4. collatorï¼šAutoProcessor æ‰“åŒ…å¤šæ¨¡æ€ =====================

@dataclass
class MedGemmaCollator:
    processor: AutoProcessor

    def __call__(self, batch) -> Dict[str, Any]:
        images = [eg["image"] for eg in batch]
        messages_list = [eg["messages"] for eg in batch]
        targets = [eg["target_text"] for eg in batch]

        texts = []
        for msgs, tgt in zip(messages_list, targets):
            chat_text = self.processor.apply_chat_template(
                msgs,
                add_generation_prompt=False,
                tokenize=False,
            )
            # æŠŠæ ‡ç­¾ä»£ç æ‹¼åœ¨åé¢ï¼Œä½œä¸ºâ€œæ­£ç¡®å›ç­”â€
            full_text = chat_text + tgt
            texts.append(full_text)

        model_inputs = self.processor(
            text=texts,
            images=images,
            padding=True,
            truncation=True,
            return_tensors="pt",
        )

        labels = model_inputs["input_ids"].clone()
        labels[labels == self.processor.tokenizer.pad_token_id] = -100
        model_inputs["labels"] = labels
        return model_inputs


# ===================== 5. åŠ è½½æ¨¡å‹ + LoRAï¼ˆè°ƒæ•´è¶…å‚ï¼šæ›´æ¸©å’Œçš„å¾®è°ƒï¼‰ =====================

def load_model_and_processor():
    print("ğŸ”§ åŠ è½½ MedGEMMA åŸºç¡€æ¨¡å‹ï¼ˆbf16 + LoRAï¼Œå…¨ç²¾æƒé‡ï¼Œä¸ç”¨ bitsandbytesï¼‰...")
    model = AutoModelForImageTextToText.from_pretrained(
        BASE_MODEL,
        dtype=torch.bfloat16,   # å¦‚ GPU ä¸æ”¯æŒ bfloat16ï¼Œåˆ™æ”¹ä¸º torch.float16 å¹¶åœ¨ TrainingArguments é‡Œ fp16=True
        device_map="auto",
    )

    processor = AutoProcessor.from_pretrained(BASE_MODEL)
    processor.tokenizer.padding_side = "right"

    # å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
    model.gradient_checkpointing_enable()
    if hasattr(model, "config"):
        model.config.use_cache = False

    # LoRA é…ç½®ï¼šæ›´â€œå¼±â€ä¸€ç‚¹ï¼ˆdropout æé«˜ï¼‰
    lora_config = LoraConfig(
        r=16,
        lora_alpha=16,
        lora_dropout=0.1,   # ä» 0.05 æé«˜åˆ° 0.1ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆå’Œç¾éš¾æ€§é—å¿˜
        bias="none",
        task_type="CAUSAL_LM",
        target_modules="all-linear",
    )

    # è®©è¾“å…¥éœ€è¦ gradï¼Œæ–¹ä¾¿ LoRA è®­ç»ƒ
    model.enable_input_require_grads()

    # æŒ‚è½½ LoRA é€‚é…å™¨
    model = get_peft_model(model, lora_config)

    trainable, total = 0, 0
    for _, p in model.named_parameters():
        total += p.numel()
        if p.requires_grad:
            trainable += p.numel()
    print(f"ğŸ“Š æ€»å‚æ•°: {total/1e6:.1f}M, å¯è®­ç»ƒ(LoRA): {trainable/1e6:.1f}M")

    return model, processor


# ===================== 6. ä¸»è®­ç»ƒå…¥å£ =====================

def main():
    # 1) å…ˆæŒ‰ç±»åˆ«åˆ†å±‚åˆ’åˆ† train/val/test
    train_csv, val_csv, test_csv = prepare_splits()

    # 2) ç”¨ HF Dataset åªåŠ è½½ train/valï¼ˆæµ‹è¯•é›†åªç•™ç»™è¯„ä¼°ï¼‰
    raw = load_dataset(
        "csv",
        data_files={"train": train_csv, "val": val_csv},
    )
    train_hf = raw["train"]
    val_hf = raw["val"]

    train_ds = DermMetadataDataset(train_hf)
    val_ds = DermMetadataDataset(val_hf)

    model, processor = load_model_and_processor()
    collator = MedGemmaCollator(processor=processor)

    # ===== è¿™é‡Œæ˜¯å…³é”®ï¼šè°ƒæ•´å¾®è°ƒå¼ºåº¦ï¼ˆæ­¥éª¤ 1ï¼‰ =====
    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        num_train_epochs=3,          # ä» 10 é™åˆ° 3ï¼Œé¿å…è¿‡æ‹Ÿåˆ & å¤§å¹…ç ´ååŸºåº§
        per_device_train_batch_size=1,
        per_device_eval_batch_size=1,
        gradient_accumulation_steps=8,
        learning_rate=5e-5,          # ä» 1e-4 é™åˆ° 5e-5ï¼Œæ›´æ¸©å’Œ
        logging_steps=10,
        save_steps=200,
        save_total_limit=2,
        bf16=True,                   # å¦‚æŠ¥é”™åˆ™æ”¹ä¸ºï¼šbf16=False, fp16=True
        fp16=False,
        report_to="none",
        remove_unused_columns=False, # ä¿ç•™ image/messages ç­‰è‡ªå®šä¹‰å­—æ®µ
        # ä¸ä½¿ç”¨ evaluation_strategyï¼Œå…¼å®¹ä½ å½“å‰ transformers ç‰ˆæœ¬
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_ds,
        eval_dataset=val_ds,
        data_collator=collator,
    )

    trainer.train()

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    model.save_pretrained(OUTPUT_DIR)
    processor.save_pretrained(OUTPUT_DIR)
    print(f"âœ… LoRA adapter å·²ä¿å­˜åˆ°: {OUTPUT_DIR}")
    print(f"âœ… è¯„ä¼°ç”¨çš„ test CSV åœ¨: {TEST_CSV}")


if __name__ == "__main__":
    main()
