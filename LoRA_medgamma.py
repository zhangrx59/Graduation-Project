# LoRA_medgamma_finetune.py
# -*- coding: utf-8 -*-

import os
from dataclasses import dataclass
from typing import Dict, Any, Tuple

import torch
from torch.utils.data import Dataset
from PIL import Image

import pandas as pd
from datasets import load_dataset
from sklearn.model_selection import train_test_split

from transformers import (
    AutoModelForImageTextToText,
    AutoProcessor,
    TrainingArguments,
    Trainer,
)
from peft import (
    LoraConfig,
    get_peft_model,
)

# ===================== 0. é…ç½®åŒºåŸŸ =====================

# åŸºç¡€æ¨¡å‹
BASE_MODEL = "google/medgemma-4b-it"

# åŸå§‹ metadata CSVï¼ˆåŒ…å«æ‰€æœ‰æ ·æœ¬ï¼‰
METADATA_CSV = r"C:\Users\zhangrx59\PycharmProjects\LoRA\metadata_isic_with_shape.csv"

# å›¾ç‰‡æ‰€åœ¨æ ¹ç›®å½• + åç¼€
IMAGE_ROOT_DIR = r"C:\Users\zhangrx59\PycharmProjects\LoRA\ISIC_dataset"
IMAGE_EXT = ".png"   # å¦‚æœæ˜¯ .jpg å°±æ”¹æˆ ".jpg"

# è¾“å‡ºçš„åˆ’åˆ†å CSV
TRAIN_CSV = METADATA_CSV.replace(".csv", "_train_5cls.csv")
VAL_CSV   = METADATA_CSV.replace(".csv", "_val_5cls.csv")
TEST_CSV  = METADATA_CSV.replace(".csv", "_test_5cls.csv")   # ç”¨äºåç»­ baseline / LoRA è¯„ä¼°

# åˆ—åï¼ˆä¸ä½ çš„æ•°æ®ä¸€è‡´ï¼‰
COL_IMAGE_ID    = "image_id"
COL_AGE         = "å¹´é¾„"
COL_SEX         = "æ€§åˆ«"
COL_FATHER_ORI  = "çˆ¶ç±è´¯"
COL_MOTHER_ORI  = "æ¯ç±è´¯"
COL_BIOPSY      = "æ˜¯å¦æ´»æ£€"
COL_SMOKE       = "æ˜¯å¦å¸çƒŸ"
COL_DRINK       = "æ˜¯å¦é¥®é…’"
COL_PESTICIDE   = "å†œè¯"
COL_SKIN_CANCER = "çš®è‚¤ç™Œç—…å²"
COL_OTHER_CA    = "ç™Œç—‡ç—…å²"
COL_TAP_WATER   = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰è‡ªæ¥æ°´"
COL_SEWER       = "ç”Ÿæ´»ç¯å¢ƒæ˜¯å¦æœ‰ä¸‹æ°´é“"
COL_PHOTOTYPE   = "çš®è‚¤å…‰å‹"
COL_REGION      = "åŒºåŸŸ"
COL_D1          = "ç›´å¾„1"
COL_D2          = "ç›´å¾„2"
COL_PRURITUS    = "ç˜™ç—’"
COL_GROWTH      = "æ˜¯å¦é•¿å¤§"
COL_PAIN        = "ç–¼ç—›"
COL_MORPH_CHANGE= "å½¢æ€å˜åŒ–"
COL_BLEEDING    = "å‡ºè¡€"
COL_ELEVATED    = "æ˜¯å¦éš†èµ·"

# çš®è‚¤ç—…åˆ†ç±»æ ‡ç­¾åˆ—ï¼ˆdx / è¯Šæ–­æ ‡ç­¾ ç­‰ï¼‰
COL_TARGET      = "dx"

# åªä¿ç•™è¿™ 5 ç±»
ALLOWED_DX = ["akiec", "bcc", "bkl", "nev", "mel"]

# LoRA adapter è¾“å‡ºç›®å½•ï¼ˆè°ƒå¥½çš„å¤§æ¨¡å‹å°±ä¿å­˜åœ¨è¿™é‡Œï¼‰
OUTPUT_DIR = r"C:\Users\zhangrx59\PycharmProjects\LoRA\medgemma_lora_derm_from_metadata"


# ===================== 1. å·¥å…·å‡½æ•°ï¼šç—…å†æ‘˜è¦æ‹¼æ¥ =====================

def yn_str(v, yes="æœ‰", no="æ— ", unk="ä¸è¯¦"):
    if isinstance(v, str):
        vs = v.strip().upper()
        if vs in ["TRUE", "T", "YES", "Y"]:
            return yes
        if vs in ["FALSE", "F", "NO", "N"]:
            return no
        if vs in ["UNK", "UNKNOWN", "NA", "NAN", "NONE", ""]:
            return unk
    if isinstance(v, (bool, int)):
        return yes if bool(v) else no
    if v != v:  # NaN
        return unk
    return str(v)


def build_clinical_note(row) -> str:
    """
    æ ¹æ®å¤šåˆ—å­—æ®µè‡ªåŠ¨æ‹¼æ¥æˆä¸€æ®µä¸­æ–‡ç—…å†æ‘˜è¦æ–‡æœ¬ã€‚
    """
    age = row.get(COL_AGE, "")
    sex = str(row.get(COL_SEX, "") or "").strip()
    region = str(row.get(COL_REGION, "") or "").strip()
    father_ori = str(row.get(COL_FATHER_ORI, "") or "").strip()
    mother_ori = str(row.get(COL_MOTHER_ORI, "") or "").strip()

    skin_ca = yn_str(row.get(COL_SKIN_CANCER))
    other_ca = yn_str(row.get(COL_OTHER_CA))
    smoke = yn_str(row.get(COL_SMOKE), yes="å¸çƒŸ", no="ä¸å¸çƒŸ")
    drink = yn_str(row.get(COL_DRINK), yes="é¥®é…’", no="ä¸é¥®é…’")
    pesticide = yn_str(row.get(COL_PESTICIDE), yes="æœ‰å†œè¯æ¥è§¦å²", no="æ— å†œè¯æ¥è§¦å²")

    tap = yn_str(row.get(COL_TAP_WATER), yes="æœ‰è‡ªæ¥æ°´", no="æ— è‡ªæ¥æ°´")
    sewer = yn_str(row.get(COL_SEWER), yes="æœ‰ä¸‹æ°´é“", no="æ— ä¸‹æ°´é“")

    phototype = row.get(COL_PHOTOTYPE, "")
    d1 = row.get(COL_D1, "")
    d2 = row.get(COL_D2, "")

    pruritus = yn_str(row.get(COL_PRURITUS))
    growth = yn_str(row.get(COL_GROWTH))
    pain = yn_str(row.get(COL_PAIN))
    morph_change = yn_str(row.get(COL_MORPH_CHANGE))
    bleeding = yn_str(row.get(COL_BLEEDING))
    elevated = yn_str(row.get(COL_ELEVATED))

    # æ€§åˆ«æ±‰åŒ–
    if isinstance(sex, str) and sex.upper() in ["MALE", "M"]:
        sex_cn = "ç”·æ€§"
    elif isinstance(sex, str) and sex.upper() in ["FEMALE", "F"]:
        sex_cn = "å¥³æ€§"
    else:
        sex_cn = sex or "æ€§åˆ«ä¸è¯¦"

    region_cn = region or "éƒ¨ä½ä¸è¯¦"

    size_str = ""
    if d1 and d2:
        size_str = f"çš®æŸçº¦ {d1}Ã—{d2} mm"
    elif d1:
        size_str = f"çš®æŸæœ€å¤§å¾„çº¦ {d1} mm"

    photo_str = f"çš®è‚¤å…‰å‹ï¼š{phototype} å‹" if phototype != "" else ""

    origin_str = ""
    if father_ori or mother_ori:
        origin_str = f"çˆ¶ç±è´¯ï¼š{father_ori}ï¼Œæ¯ç±è´¯ï¼š{mother_ori}ã€‚"

    parts = []
    parts.append(f"{age}å²{sex_cn}ï¼Œ{region_cn}çš®è‚¤ç—…å˜ã€‚")
    if size_str:
        parts.append(size_str + "ã€‚")
    if origin_str:
        parts.append(origin_str)

    parts.append(f"æ—¢å¾€çš®è‚¤ç™Œç—…å²ï¼š{skin_ca}ï¼›å…¶ä»–æ¶æ€§è‚¿ç˜¤ç—…å²ï¼š{other_ca}ã€‚")
    parts.append(f"ç”Ÿæ´»æ–¹å¼ï¼š{smoke}ï¼Œ{drink}ï¼Œ{pesticide}ã€‚")
    parts.append(f"å±…ä½ç¯å¢ƒï¼š{tap}ï¼Œ{sewer}ã€‚")
    if photo_str:
        parts.append(photo_str + "ã€‚")

    parts.append(
        f"ç—‡çŠ¶ä½“å¾ï¼šç˜™ç—’{pruritus}ï¼Œæ˜¯å¦é•¿å¤§{growth}ï¼Œç–¼ç—›{pain}ï¼Œ"
        f"å½¢æ€å˜åŒ–{morph_change}ï¼Œå‡ºè¡€{bleeding}ï¼Œéš†èµ·{elevated}ã€‚"
    )

    return "".join(parts)


def normalize_dx(label: str) -> str:
    if not isinstance(label, str):
        return ""
    s = label.strip().lower()
    if s == "nv":
        s = "nev"
    return s


# ===================== 2. æŒ‰ç±»åˆ«å‡åŒ€åˆ’åˆ† train/val/testï¼ˆé¿å…æ³„éœ²ï¼‰ =====================

def prepare_splits(
    seed: int = 42,
    train_ratio: float = 0.7,
    val_ratio: float = 0.15,
    test_ratio: float = 0.15,
) -> Tuple[str, str, str]:
    """
    ä» METADATA_CSV ä¸­ï¼š
    - ä»…ä¿ç•™ dx âˆˆ ALLOWED_DX çš„æ ·æœ¬
    - æŒ‰ç±»åˆ« stratify åˆ’åˆ† train/val/test
    - ä¿å­˜åˆ° *_train_5cls.csv / *_val_5cls.csv / *_test_5cls.csv
    """
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6

    if os.path.exists(TRAIN_CSV) and os.path.exists(VAL_CSV) and os.path.exists(TEST_CSV):
        print("ğŸ“ å‘ç°å·²æœ‰åˆ’åˆ†æ–‡ä»¶ï¼Œç›´æ¥å¤ç”¨ï¼š")
        print(f"  train: {TRAIN_CSV}")
        print(f"  val  : {VAL_CSV}")
        print(f"  test : {TEST_CSV}")
        return TRAIN_CSV, VAL_CSV, TEST_CSV

    print(f"ğŸ“„ è¯»å–åŸå§‹ CSV: {METADATA_CSV}")
    df = pd.read_csv(METADATA_CSV, encoding="utf-8")

    if COL_TARGET not in df.columns:
        raise ValueError(f"CSV ä¸­æ‰¾ä¸åˆ°æ ‡ç­¾åˆ— {COL_TARGET!r}")

    # å½’ä¸€åŒ– dx
    df["dx"] = df[COL_TARGET].apply(normalize_dx)
    df = df[df["dx"].isin(ALLOWED_DX)].copy()

    print(f"âœ… è¿‡æ»¤ååªä¿ç•™ {ALLOWED_DX}ï¼Œå‰©ä½™æ ·æœ¬æ•°: {len(df)}")

    # æŒ‰ dx åˆ†å±‚åˆ’åˆ† train / (val+test)
    df_train, df_tmp = train_test_split(
        df,
        test_size=val_ratio + test_ratio,
        stratify=df["dx"],
        random_state=seed,
    )

    # å†æŠŠ tmp åˆ†æˆ val/test
    tmp_ratio = test_ratio / (val_ratio + test_ratio)
    df_val, df_test = train_test_split(
        df_tmp,
        test_size=tmp_ratio,
        stratify=df_tmp["dx"],
        random_state=seed,
    )

    print("ğŸ“Š æŒ‰ç±»åˆ«åˆ†å±‚åˆ’åˆ†å®Œæˆï¼š")
    print("  train:", df_train["dx"].value_counts().to_dict())
    print("  val  :", df_val["dx"].value_counts().to_dict())
    print("  test :", df_test["dx"].value_counts().to_dict())

    # ä¿å­˜
    df_train.to_csv(TRAIN_CSV, index=False, encoding="utf-8-sig")
    df_val.to_csv(VAL_CSV, index=False, encoding="utf-8-sig")
    df_test.to_csv(TEST_CSV, index=False, encoding="utf-8-sig")

    print("ğŸ’¾ å·²ä¿å­˜åˆ’åˆ†æ–‡ä»¶ï¼š")
    print(f"  train â†’ {TRAIN_CSV}")
    print(f"  val   â†’ {VAL_CSV}")
    print(f"  test  â†’ {TEST_CSV}")

    return TRAIN_CSV, VAL_CSV, TEST_CSV


# ===================== 3. Datasetï¼šç—…ä¾‹ + å›¾åƒ â†’ åˆ†ç±»æ ‡ç­¾ =====================

class DermMetadataDataset(Dataset):
    """
    åŸºäºåˆ’åˆ†åçš„ CSV çš„ Datasetï¼š
    - image: ç”± å›¾ç‰‡ID + IMAGE_ROOT_DIR + IMAGE_EXT æ‹¼è·¯å¾„
    - clinical_note: ç”±å¤šåˆ—å­—æ®µè‡ªåŠ¨æ‹¼æ¥
    - target_text: çš®è‚¤ç—…åˆ†ç±»æ ‡ç­¾ï¼ˆakiec/bcc/bkl/nev/melï¼‰ï¼Œä½œä¸ºç”Ÿæˆç›®æ ‡
    """
    def __init__(self, hf_dataset):
        self.ds = hf_dataset

    def __len__(self):
        return len(self.ds)

    def __getitem__(self, idx):
        row = self.ds[idx]

        image_id = str(row[COL_IMAGE_ID])
        image_path = os.path.join(IMAGE_ROOT_DIR, image_id + IMAGE_EXT)
        image = Image.open(image_path).convert("RGB")

        clinical_note = build_clinical_note(row)
        # æ ‡ç­¾ç»Ÿä¸€æˆå°å†™å­—ç¬¦ä¸²
        target_text = normalize_dx(str(row[COL_TARGET]))

        # æ„é€ å¤šæ¨¡æ€å¯¹è¯ï¼š
        messages = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "You are a dermatology assistant. "
                            "Given the clinical note and the skin lesion image, "
                            "your task is to classify the skin lesion into one of the following dx codes: "
                            "akiec, bcc, bkl, nev, mel. "
                            "Only output ONE code (akiec/bcc/bkl/nev/mel) as the final answer. "
                            "Do NOT output any other words or explanations."
                        ),
                    }
                ],
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "ä¸´åºŠç—…å†æ‘˜è¦å¦‚ä¸‹ï¼š\n"
                            f"{clinical_note}\n\n"
                            "è¯·ç»“åˆç—…å†å’Œä¸‹æ–¹çš„çš®è‚¤ç—…å˜å›¾åƒï¼Œåˆ¤æ–­è¯¥ç—…å˜æœ€å¯èƒ½å±äºå“ªä¸€ç±»ï¼Œ"
                            "å¹¶åªè¾“å‡ºä¸€ä¸ª dx ä»£ç ï¼ˆakiec/bcc/bkl/nev/melï¼‰ä½œä¸ºç­”æ¡ˆï¼š"
                        ),
                    },
                    {"type": "image", "image": image},
                ],
            },
        ]

        return {
            "messages": messages,
            "image": image,
            "target_text": target_text,
        }


# ===================== 4. collatorï¼šAutoProcessor æ‰“åŒ…å¤šæ¨¡æ€ =====================

@dataclass
class MedGemmaCollator:
    processor: AutoProcessor

    def __call__(self, batch) -> Dict[str, Any]:
        images = [eg["image"] for eg in batch]
        messages_list = [eg["messages"] for eg in batch]
        targets = [eg["target_text"] for eg in batch]

        texts = []
        for msgs, tgt in zip(messages_list, targets):
            chat_text = self.processor.apply_chat_template(
                msgs,
                add_generation_prompt=False,
                tokenize=False,
            )
            # æŠŠæ ‡ç­¾ä»£ç æ‹¼åœ¨åé¢ï¼Œä½œä¸ºæ­£ç¡®å›ç­”
            full_text = chat_text + tgt
            texts.append(full_text)

        model_inputs = self.processor(
            text=texts,
            images=images,
            padding=True,
            truncation=True,
            return_tensors="pt",
        )

        labels = model_inputs["input_ids"].clone()
        labels[labels == self.processor.tokenizer.pad_token_id] = -100
        model_inputs["labels"] = labels
        return model_inputs


# ===================== 5. åŠ è½½æ¨¡å‹ + LoRAï¼ˆbf16ï¼Œå…¨ç²¾ï¼‰ =====================

def load_model_and_processor():
    print("ğŸ”§ åŠ è½½ MedGemma åŸºç¡€æ¨¡å‹ï¼ˆbf16 + LoRAï¼Œå…¨ç²¾æƒé‡ï¼Œä¸ç”¨ bitsandbytesï¼‰...")
    model = AutoModelForImageTextToText.from_pretrained(
        BASE_MODEL,
        dtype=torch.bfloat16,   # å¦‚æœ GPU ä¸æ”¯æŒ bf16ï¼Œå°±æ”¹æˆ torch.float16 å¹¶åœ¨ TrainingArguments é‡Œ fp16=True
        device_map="auto",
    )

    processor = AutoProcessor.from_pretrained(BASE_MODEL)
    processor.tokenizer.padding_side = "right"

    # å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
    model.gradient_checkpointing_enable()
    if hasattr(model, "config"):
        model.config.use_cache = False

    lora_config = LoraConfig(
        r=16,
        lora_alpha=16,
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM",
        target_modules="all-linear",
    )

    # è®©è¾“å…¥éœ€è¦ gradï¼Œæ–¹ä¾¿ LoRA è®­ç»ƒ
    model.enable_input_require_grads()

    # æŒ‚è½½ LoRA é€‚é…å™¨
    model = get_peft_model(model, lora_config)

    trainable, total = 0, 0
    for _, p in model.named_parameters():
        total += p.numel()
        if p.requires_grad:
            trainable += p.numel()
    print(f"ğŸ“Š æ€»å‚æ•°: {total/1e6:.1f}M, å¯è®­ç»ƒ(LoRA): {trainable/1e6:.1f}M")

    return model, processor


# ===================== 6. ä¸»è®­ç»ƒå…¥å£ =====================

def main():
    # 1) å…ˆæŒ‰ç±»åˆ«åˆ†å±‚åˆ’åˆ† train/val/test
    train_csv, val_csv, test_csv = prepare_splits()

    # 2) ç”¨ HF Dataset åªåŠ è½½ train/valï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰
    raw = load_dataset(
        "csv",
        data_files={"train": train_csv, "val": val_csv},
    )
    train_hf = raw["train"]
    val_hf = raw["val"]

    train_ds = DermMetadataDataset(train_hf)
    val_ds = DermMetadataDataset(val_hf)

    model, processor = load_model_and_processor()
    collator = MedGemmaCollator(processor=processor)

    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        num_train_epochs=2,
        per_device_train_batch_size=1,
        per_device_eval_batch_size=1,
        gradient_accumulation_steps=8,
        learning_rate=1e-4,
        logging_steps=10,
        save_steps=200,
        save_total_limit=2,
        bf16=True,  # å¦‚æœä¸æ”¯æŒ bf16 å°±æ”¹æˆ fp16=True
        fp16=False,
        report_to="none",
        remove_unused_columns=False,
        eval_strategy="steps",  # â† æ—§ç‰ˆæœ¬ transformers çš„å†™æ³•
        eval_steps=200,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_ds,
        eval_dataset=val_ds,
        data_collator=collator,
    )

    trainer.train()

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    model.save_pretrained(OUTPUT_DIR)
    processor.save_pretrained(OUTPUT_DIR)
    print(f"âœ… LoRA adapter å·²ä¿å­˜åˆ°: {OUTPUT_DIR}")
    print(f"âœ… è¯„ä¼°ç”¨çš„ test CSV åœ¨: {TEST_CSV}")


if __name__ == "__main__":
    main()
